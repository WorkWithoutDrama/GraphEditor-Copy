#!/usr/bin/env python3
"""
API —Å –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–µ–π LLM (Ollama) –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –º–æ–¥–µ–ª–µ–π
"""

import http.server
import socketserver
import json
import sys
import datetime
import os
import subprocess
import threading
import time

# –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –æ—Ç–∫–ª—é—á–∞–µ–º –±—É—Ñ–µ—Ä–∏–∑–∞—Ü–∏—é
os.environ['PYTHONUNBUFFERED'] = '1'
sys.stdout = os.fdopen(sys.stdout.fileno(), 'w', 1)

print("=" * 60)
print("üöÄ API –° LLM - –ò–ù–¢–ï–ì–†–ê–¶–ò–Ø –° OLLAMA")
print("=" * 60)
print("–≠—Ç–æ —Å–æ–æ–±—â–µ–Ω–∏–µ –î–û–õ–ñ–ù–û –±—ã—Ç—å –≤–∏–¥–Ω–æ —Å—Ä–∞–∑—É!")
sys.stdout.flush()

class LLMAPIHandler(http.server.BaseHTTPRequestHandler):
    
    def log_message(self, format, *args):
        """–ö–∞—Å—Ç–æ–º–∏–∑–∞—Ü–∏—è –ª–æ–≥–æ–≤ - –≤—ã–≤–æ–¥–∏–º –í–°–ï–ì–î–ê"""
        message = f"{self.address_string()} - {format % args}"
        print(f"üîπ {message}")
        sys.stdout.flush()
    
    def do_GET(self):
        if self.path == "/api/health":
            print("üì° –û–ë–†–ê–ë–û–¢–ö–ê GET /api/health")
            sys.stdout.flush()
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å LLM
            llm_status = self.check_llm_status()
            
            self.send_response(200)
            self.send_header("Content-Type", "application/json")
            self.send_header("Access-Control-Allow-Origin", "*")
            self.end_headers()
            self.wfile.write(json.dumps({
                "status": "ok", 
                "api": "llm",
                "llm_available": llm_status["available"],
                "llm_status": llm_status["status"]
            }).encode())
            sys.stdout.flush()
        else:
            self.send_response(404)
            self.send_header("Content-Type", "application/json")
            self.end_headers()
            self.wfile.write(json.dumps({"error": "Not found"}).encode())
    
    def do_POST(self):
        if self.path == "/api/generate-model":
            print("üì• –ü–û–õ–£–ß–ï–ù POST –ó–ê–ü–†–û–° /api/generate-model")
            sys.stdout.flush()
            
            try:
                content_length = int(self.headers.get('Content-Length', 0))
                post_data = self.rfile.read(content_length)
                data = json.loads(post_data.decode('utf-8'))
                text = data.get('text', '')
                
                print(f"üìÑ –¢–µ–∫—Å—Ç –∑–∞–ø—Ä–æ—Å–∞: {text[:100]}...")
                print(f"üìè –î–ª–∏–Ω–∞: {len(text)} —Å–∏–º–≤–æ–ª–æ–≤")
                sys.stdout.flush()
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å LLM
                llm_status = self.check_llm_status()
                if not llm_status["available"]:
                    print(f"‚ùå LLM –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: {llm_status['status']}")
                    sys.stdout.flush()
                    
                    # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—à–∏–±–∫—É
                    self.send_response(500)
                    self.send_header("Content-Type", "application/json")
                    self.send_header("Access-Control-Allow-Origin", "*")
                    self.end_headers()
                    self.wfile.write(json.dumps({
                        "success": False,
                        "error": f"LLM –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: {llm_status['status']}"
                    }).encode())
                    return
                
                print("üîÑ –ó–ê–ü–£–°–ö–ê–Æ LLM –î–õ–Ø –ê–ù–ê–õ–ò–ó–ê –¢–ó...")
                sys.stdout.flush()
                
                # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –ø—Ä–æ–º–ø—Ç
                prompt = self.generate_prompt(text)
                
                print("ü§ñ –û–¢–ü–†–ê–í–õ–Ø–Æ –ó–ê–ü–†–û–° –ö LLM...")
                print(f"üìù –ü—Ä–æ–º–ø—Ç (–ø–µ—Ä–≤—ã–µ 500 —Å–∏–º–≤–æ–ª–æ–≤): {prompt[:500]}...")
                sys.stdout.flush()
                
                # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å –∫ LLM
                llm_response = self.query_llm(prompt)
                
                if llm_response["success"]:
                    print("‚úÖ LLM –û–¢–í–ï–¢–ò–õ –£–°–ü–ï–®–ù–û!")
                    print(f"üìÑ –û—Ç–≤–µ—Ç LLM (–ø–µ—Ä–≤—ã–µ 500 —Å–∏–º–≤–æ–ª–æ–≤): {llm_response['response'][:500]}...")
                    sys.stdout.flush()
                    
                    # –ü–∞—Ä—Å–∏–º –∏ –≤–∞–ª–∏–¥–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç LLM
                    model = self.parse_llm_response(llm_response["response"])
                    
                    if model:
                        print("üéØ –ú–û–î–ï–õ–¨ –°–ì–ï–ù–ï–†–ò–†–û–í–ê–ù–ê LLM!")
                        sys.stdout.flush()
                        
                        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —É—Å–ø–µ—à–Ω—ã–π –æ—Ç–≤–µ—Ç
                        response = {"success": True, "model": model}
                        self.send_response(200)
                        self.send_header("Content-Type", "application/json")
                        self.send_header("Access-Control-Allow-Origin", "*")
                        self.end_headers()
                        self.wfile.write(json.dumps(response, ensure_ascii=False).encode())
                    else:
                        print("‚ùå –ù–ï –£–î–ê–õ–û–°–¨ –†–ê–°–ü–ê–†–°–ò–¢–¨ –û–¢–í–ï–¢ LLM")
                        sys.stdout.flush()
                        
                        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—à–∏–±–∫—É –ø–∞—Ä—Å–∏–Ω–≥–∞
                        self.send_response(500)
                        self.send_header("Content-Type", "application/json")
                        self.send_header("Access-Control-Allow-Origin", "*")
                        self.end_headers()
                        self.wfile.write(json.dumps({
                            "success": False,
                            "error": "–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å –æ—Ç–≤–µ—Ç LLM"
                        }).encode())
                else:
                    print(f"‚ùå –û–®–ò–ë–ö–ê LLM: {llm_response['error']}")
                    sys.stdout.flush()
                    
                    # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—à–∏–±–∫—É LLM
                    self.send_response(500)
                    self.send_header("Content-Type", "application/json")
                    self.send_header("Access-Control-Allow-Origin", "*")
                    self.end_headers()
                    self.wfile.write(json.dumps({
                        "success": False,
                        "error": f"–û—à–∏–±–∫–∞ LLM: {llm_response['error']}"
                    }).encode())
                
                print("‚úÖ –û–¢–í–ï–¢ –û–¢–ü–†–ê–í–õ–ï–ù")
                sys.stdout.flush()
                
            except Exception as e:
                print(f"‚ùå –û–®–ò–ë–ö–ê: {e}")
                import traceback
                traceback.print_exc()
                sys.stdout.flush()
                self.send_response(500)
                self.send_header("Content-Type", "application/json")
                self.end_headers()
                self.wfile.write(json.dumps({"success": False, "error": str(e)}).encode())
        else:
            self.send_response(404)
            self.send_header("Content-Type", "application/json")
            self.end_headers()
            self.wfile.write(json.dumps({"error": "Not found"}).encode())
    
    def check_llm_status(self):
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å LLM (Ollama)"""
        print("üîç –ü–†–û–í–ï–†–Ø–Æ –î–û–°–¢–£–ü–ù–û–°–¢–¨ LLM...")
        sys.stdout.flush()
        
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –∑–∞–ø—É—â–µ–Ω –ª–∏ —Å–µ—Ä–≤–µ—Ä Ollama
            result = subprocess.run(
                ["curl", "-s", "http://localhost:11434/api/tags"],
                capture_output=True,
                text=True,
                timeout=5
            )
            
            if result.returncode == 0:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –º–æ–¥–µ–ª–∏ llama3.2
                if "llama3.2" in result.stdout:
                    print("‚úÖ LLM –î–û–°–¢–£–ü–ï–ù (Ollama —Å llama3.2)")
                    sys.stdout.flush()
                    return {"available": True, "status": "Ollama —Å –º–æ–¥–µ–ª—å—é llama3.2"}
                else:
                    print("‚ö†Ô∏è  Ollama –∑–∞–ø—É—â–µ–Ω, –Ω–æ –º–æ–¥–µ–ª—å llama3.2 –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
                    sys.stdout.flush()
                    return {"available": False, "status": "–ú–æ–¥–µ–ª—å llama3.2 –Ω–µ –Ω–∞–π–¥–µ–Ω–∞"}
            else:
                print("‚ùå –°–µ—Ä–≤–µ—Ä Ollama –Ω–µ –æ—Ç–≤–µ—á–∞–µ—Ç")
                sys.stdout.flush()
                return {"available": False, "status": "–°–µ—Ä–≤–µ—Ä Ollama –Ω–µ –∑–∞–ø—É—â–µ–Ω"}
                
        except subprocess.TimeoutExpired:
            print("‚ùå –¢–∞–π–º–∞—É—Ç –ø—Ä–æ–≤–µ—Ä–∫–∏ LLM")
            sys.stdout.flush()
            return {"available": False, "status": "–¢–∞–π–º–∞—É—Ç –ø—Ä–æ–≤–µ—Ä–∫–∏"}
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ LLM: {e}")
            sys.stdout.flush()
            return {"available": False, "status": f"–û—à–∏–±–∫–∞: {str(e)}"}
    
    def generate_prompt(self, text):
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –ø—Ä–æ–º–ø—Ç –¥–ª—è LLM –Ω–∞ –æ—Å–Ω–æ–≤–µ –¢–ó"""
        prompt_template = """–¢—ã - –∞–Ω–∞–ª–∏—Ç–∏–∫ –ø—Ä–æ—Ü–µ—Å—Å–æ–≤. –¢–≤–æ—è –∑–∞–¥–∞—á–∞ - –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–µ –∑–∞–¥–∞–Ω–∏–µ –∏ —Å–æ–∑–¥–∞—Ç—å —Ñ–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—É—é –º–æ–¥–µ–ª—å –ø—Ä–æ—Ü–µ—Å—Å–æ–≤.

–ê–ù–ê–õ–ò–ó–ò–†–£–ô —Å–ª–µ–¥—É—é—â–µ–µ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–µ –∑–∞–¥–∞–Ω–∏–µ:

"""
        prompt_template += text
        prompt_template += """

–ò–ù–°–¢–†–£–ö–¶–ò–ò –ü–û –ê–ù–ê–õ–ò–ó–£:

1. –ò–î–ï–ù–¢–ò–§–ò–¶–ò–†–£–ô –î–ï–ô–°–¢–í–ò–Ø:
   - –ù–∞–π–¥–∏—Ç–µ –≤—Å–µ –∫–ª—é—á–µ–≤—ã–µ –¥–µ–π—Å—Ç–≤–∏—è/–ø—Ä–æ—Ü–µ—Å—Å—ã –≤ –¢–ó
   - –ö–∞–∂–¥–æ–µ –¥–µ–π—Å—Ç–≤–∏–µ –¥–æ–ª–∂–Ω–æ –∏–º–µ—Ç—å —É–Ω–∏–∫–∞–ª—å–Ω—ã–π ID –≤ —Ñ–æ—Ä–º–∞—Ç–µ "a" + 5 —Ü–∏—Ñ—Ä (–Ω–∞–ø—Ä–∏–º–µ—Ä: a00001)
   - –ù–∞–∑–≤–∞–Ω–∏–µ –¥–µ–π—Å—Ç–≤–∏—è –¥–æ–ª–∂–Ω–æ –∫—Ä–∞—Ç–∫–æ –æ–ø–∏—Å—ã–≤–∞—Ç—å –ø—Ä–æ—Ü–µ—Å—Å

2. –ò–î–ï–ù–¢–ò–§–ò–¶–ò–†–£–ô –û–ë–™–ï–ö–¢–´ –ò –ò–• –°–û–°–¢–û–Ø–ù–ò–Ø:
   - –ù–∞–π–¥–∏—Ç–µ –≤—Å–µ –æ–±—ä–µ–∫—Ç—ã —Å–∏—Å—Ç–µ–º—ã (—Å—É—â–Ω–æ—Å—Ç–∏, —Ä–µ—Å—É—Ä—Å—ã)
   - –î–ª—è –∫–∞–∂–¥–æ–≥–æ –æ–±—ä–µ–∫—Ç–∞ –æ–ø—Ä–µ–¥–µ–ª–∏—Ç–µ –≤–æ–∑–º–æ–∂–Ω—ã–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è
   - –ö–∞–∂–¥—ã–π –æ–±—ä–µ–∫—Ç –¥–æ–ª–∂–µ–Ω –∏–º–µ—Ç—å —É–Ω–∏–∫–∞–ª—å–Ω—ã–π ID –≤ —Ñ–æ—Ä–º–∞—Ç–µ "o" + 5 —Ü–∏—Ñ—Ä (–Ω–∞–ø—Ä–∏–º–µ—Ä: o00001)
   - –ö–∞–∂–¥–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –¥–æ–ª–∂–Ω–æ –∏–º–µ—Ç—å —É–Ω–∏–∫–∞–ª—å–Ω—ã–π ID –≤ —Ñ–æ—Ä–º–∞—Ç–µ "s" + 5 —Ü–∏—Ñ—Ä (–Ω–∞–ø—Ä–∏–º–µ—Ä: s00001)
   - –û–±—ä–µ–∫—Ç+—Å–æ—Å—Ç–æ—è–Ω–∏–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç—Å—è –∫–∞–∫ –µ–¥–∏–Ω–æ–µ —Ü–µ–ª–æ–µ (–Ω–∞–ø—Ä–∏–º–µ—Ä: "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å: –Ω–µ–∞–∫—Ç–∏–≤–µ–Ω")

3. –û–ü–†–ï–î–ï–õ–ò –°–í–Ø–ó–ò:
   - –î–ª—è –∫–∞–∂–¥–æ–≥–æ –¥–µ–π—Å—Ç–≤–∏—è –Ω–∞–π–¥–∏—Ç–µ:
     * –ö–∞–∫–∏–µ –æ–±—ä–µ–∫—Ç—ã –≤ –∫–∞–∫–∏—Ö —Å–æ—Å—Ç–æ—è–Ω–∏—è—Ö –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã –¥–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –¥–µ–π—Å—Ç–≤–∏—è (–Ω–∞—á–∞–ª—å–Ω—ã–µ —É—Å–ª–æ–≤–∏—è)
     * –í –∫–∞–∫–∏–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è –ø–µ—Ä–µ—Ö–æ–¥—è—Ç –æ–±—ä–µ–∫—Ç—ã –ø–æ—Å–ª–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –¥–µ–π—Å—Ç–≤–∏—è (–∫–æ–Ω–µ—á–Ω—ã–µ —É—Å–ª–æ–≤–∏—è)
   - –°–≤—è–∑–∏ –∏–º–µ—é—Ç —Ñ–æ—Ä–º–∞—Ç: "–æ–±—ä–µ–∫—Ç+—Å–æ—Å—Ç–æ—è–Ω–∏–µ" ‚Üí "–¥–µ–π—Å—Ç–≤–∏–µ" ‚Üí "–æ–±—ä–µ–∫—Ç+—Å–æ—Å—Ç–æ—è–Ω–∏–µ"
   - connection_out - ID –∏—Å—Ç–æ—á–Ω–∏–∫–∞ (–Ω–∞—á–∞–ª—å–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –∏–ª–∏ –¥–µ–π—Å—Ç–≤–∏–µ)
   - connection_in - ID —Ü–µ–ª–∏ (–¥–µ–π—Å—Ç–≤–∏–µ –∏–ª–∏ –∫–æ–Ω–µ—á–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ)

4. –§–û–†–ú–ê–¢ –í–´–í–û–î–ê:
   - –í—ã–≤–µ–¥–∏ –¢–û–õ–¨–ö–û –≤–∞–ª–∏–¥–Ω—ã–π JSON –±–µ–∑ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞
   - JSON –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å —Ç—Ä–∏ –º–∞—Å—Å–∏–≤–∞: model_actions, model_objects, model_connections
   - –í—Å–µ ID –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –≤ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ
   - –ï—Å–ª–∏ –æ–±—ä–µ–∫—Ç–∞/–¥–µ–π—Å—Ç–≤–∏—è/—Å–æ—Å—Ç–æ—è–Ω–∏—è –Ω–µ—Ç –≤ –º–æ–¥–µ–ª–∏ - –¥–æ–±–∞–≤—å –µ–≥–æ

5. –ü–†–ò–ú–ï–† –î–õ–Ø –¢–ó "–†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è":
   - –î–µ–π—Å—Ç–≤–∏–µ: "–†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è" (a00001)
   - –û–±—ä–µ–∫—Ç: "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å" (o00001) —Å —Å–æ—Å—Ç–æ—è–Ω–∏—è–º–∏: "–Ω–µ–∑–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω" (s00001), "–∑–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω" (s00002)
   - –°–≤—è–∑—å: o00001s00001 ‚Üí a00001 ‚Üí o00001s00002

–í–ï–†–ù–ò –¢–û–õ–¨–ö–û JSON –û–¢–í–ï–¢:"""
        
        return prompt_template
    
    def query_llm(self, prompt):
        """–û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –∑–∞–ø—Ä–æ—Å –∫ LLM (Ollama)"""
        print("ü§ñ –í–´–ü–û–õ–ù–Ø–Æ –ó–ê–ü–†–û–° –ö LLM...")
        sys.stdout.flush()
        
        try:
            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –∑–∞–ø—Ä–æ—Å –∫ Ollama API
            request_data = {
                "model": "llama3.2",
                "prompt": prompt,
                "stream": False,
                "options": {
                    "temperature": 0.7,
                    "num_predict": 2000
                }
            }
            
            # –í—ã–ø–æ–ª–Ω—è–µ–º –∑–∞–ø—Ä–æ—Å —á–µ—Ä–µ–∑ curl
            curl_command = [
                "curl", "-s",
                "-X", "POST",
                "http://localhost:11434/api/generate",
                "-H", "Content-Type: application/json",
                "-d", json.dumps(request_data)
            ]
            
            print(f"üöÄ –ó–ê–ü–£–°–ö–ê–Æ CURL: {' '.join(curl_command[:10])}...")
            sys.stdout.flush()
            
            result = subprocess.run(
                curl_command,
                capture_output=True,
                text=True,
                timeout=30  # 30 —Å–µ–∫—É–Ω–¥ —Ç–∞–π–º–∞—É—Ç –¥–ª—è LLM
            )
            
            if result.returncode == 0:
                print("‚úÖ LLM –û–¢–í–ï–¢–ò–õ")
                sys.stdout.flush()
                
                try:
                    response_data = json.loads(result.stdout)
                    if "response" in response_data:
                        return {
                            "success": True,
                            "response": response_data["response"]
                        }
                    else:
                        print(f"‚ùå –ù–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞ LLM: {result.stdout[:200]}")
                        sys.stdout.flush()
                        return {
                            "success": False,
                            "error": "–ù–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞ LLM"
                        }
                except json.JSONDecodeError:
                    print(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å JSON –æ—Ç LLM: {result.stdout[:200]}")
                    sys.stdout.flush()
                    return {
                        "success": False,
                        "error": "–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å JSON –æ—Ç LLM"
                    }
            else:
                print(f"‚ùå –û—à–∏–±–∫–∞ curl: {result.stderr}")
                sys.stdout.flush()
                return {
                    "success": False,
                    "error": f"–û—à–∏–±–∫–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞–ø—Ä–æ—Å–∞: {result.stderr}"
                }
                
        except subprocess.TimeoutExpired:
            print("‚ùå –¢–∞–π–º–∞—É—Ç –∑–∞–ø—Ä–æ—Å–∞ –∫ LLM (30 —Å–µ–∫—É–Ω–¥)")
            sys.stdout.flush()
            return {
                "success": False,
                "error": "–¢–∞–π–º–∞—É—Ç –∑–∞–ø—Ä–æ—Å–∞ –∫ LLM"
            }
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ –∫ LLM: {e}")
            sys.stdout.flush()
            return {
                "success": False,
                "error": f"–û—à–∏–±–∫–∞: {str(e)}"
            }
    
    def parse_llm_response(self, response):
        """–ü–∞—Ä—Å–∏—Ç –∏ –≤–∞–ª–∏–¥–∏—Ä—É–µ—Ç –æ—Ç–≤–µ—Ç LLM"""
        print("üîç –ü–ê–†–°–ò–ù–ì –û–¢–í–ï–¢–ê LLM...")
        sys.stdout.flush()
        
        try:
            # –ò—â–µ–º JSON –≤ –æ—Ç–≤–µ—Ç–µ
            json_start = response.find('{')
            json_end = response.rfind('}') + 1
            
            if json_start == -1 or json_end == 0:
                print("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω JSON –≤ –æ—Ç–≤–µ—Ç–µ LLM")
                print(f"–û—Ç–≤–µ—Ç: {response[:500]}...")
                sys.stdout.flush()
                return None
            
            json_str = response[json_start:json_end]
            model = json.loads(json_str)
            
            # –ë–∞–∑–æ–≤–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è
            if not all(key in model for key in ["model_actions", "model_objects", "model_connections"]):
                print("‚ùå –ù–µ–ø–æ–ª–Ω–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ JSON")
                sys.stdout.flush()
                return None
            
            print(f"‚úÖ JSON –†–ê–°–ü–ê–†–°–ï–ù: {len(model['model_actions'])} –¥–µ–π—Å—Ç–≤–∏–π, {len(model['model_objects'])} –æ–±—ä–µ–∫—Ç–æ–≤, {len(model['model_connections'])} —Å–≤—è–∑–µ–π")
            sys.stdout.flush()
            
            return model
            
        except json.JSONDecodeError as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON: {e}")
            print(f"–û—Ç–≤–µ—Ç: {response[:500]}...")
            sys.stdout.flush()
            return None
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ: {e}")
            sys.stdout.flush()
            return None

def run_server(port=5001):
    """–ó–∞–ø—É—Å–∫ —Å–µ—Ä–≤–µ—Ä–∞ —Å LLM"""
    handler = LLMAPIHandler
    
    for p in range(port, port + 20):
        try:
            server = socketserver.TCPServer(("", p), handler)
            print(f"‚úÖ API –° LLM –∑–∞–ø—É—â–µ–Ω –Ω–∞ –ø–æ—Ä—Ç—É {p}")
            print(f"üì° GET  http://localhost:{p}/api/health")
            print(f"üì° POST http://localhost:{p}/api/generate-model")
            print("ü§ñ LLM: –ò–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω —Å Ollama (llama3.2)")
            print("üõë –î–ª—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∏: Ctrl+C")
            sys.stdout.flush()
            
            # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –ø–æ—Ä—Ç
            with open('api_port.txt', 'w') as f:
                f.write(str(p))
            sys.stdout.flush()
            
            server.serve_forever()
            break
        except OSError as e:
            if "Address already in use" in str(e):
                continue
            else:
                raise

if __name__ == "__main__":
    run_server()