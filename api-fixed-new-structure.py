#!/usr/bin/env python3
"""
AI API Server –¥–ª—è Graph Editor
–í–µ—Ä—Å–∏—è —Å –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–º –ø—Ä–æ–º–ø—Ç–æ–º —Å–æ–≥–ª–∞—Å–Ω–æ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è–º
"""

import http.server
import socketserver
import json
import os
import logging
from typing import Dict, Any
import urllib.request
import urllib.error
import time
import re

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class LLMClient:
    """–ö–ª–∏–µ–Ω—Ç –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å LLM (Ollama/DeepSeek)"""
    
    def __init__(self, provider: str = "ollama"):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è LLM –∫–ª–∏–µ–Ω—Ç–∞
        
        Args:
            provider: –ü–æ—Å—Ç–∞–≤—â–∏–∫ LLM ("ollama" –∏–ª–∏ "deepseek")
        """
        self.provider = provider.lower()
        
        # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –¥–ª—è —Ä–∞–∑–Ω—ã—Ö –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤
        self.config = {
            "ollama": {
                "base_url": "http://localhost:11434",
                "model": "llama3.2",
                "endpoint": "/api/generate"
            },
            "deepseek": {
                "base_url": "https://api.deepseek.com",
                "model": "deepseek-chat",
                "api_key_env": "DEEPSEEK_API_KEY"
            }
        }
        
        if self.provider not in self.config:
            raise ValueError(f"–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π –ø—Ä–æ–≤–∞–π–¥–µ—Ä: {self.provider}")
    
    def generate_model(self, text: str) -> Dict:
        """
        –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –º–æ–¥–µ–ª—å —Å–∏—Å—Ç–µ–º—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–µ–∫—Å—Ç–∞ –¢–ó
        
        Args:
            text: –¢–µ–∫—Å—Ç —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–≥–æ –∑–∞–¥–∞–Ω–∏—è
            
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å –º–æ–¥–µ–ª—å—é —Å–∏—Å—Ç–µ–º—ã –≤ –Ω–æ–≤–æ–º —Ñ–æ—Ä–º–∞—Ç–µ
        """
        if self.provider == "ollama":
            return self._generate_with_ollama_fixed(text)
        elif self.provider == "deepseek":
            return self._generate_with_deepseek_fixed(text)
        else:
            raise ValueError(f"–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π –ø—Ä–æ–≤–∞–π–¥–µ—Ä: {self.provider}")
    
    def _generate_with_ollama_fixed(self, text: str) -> Dict:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º Ollama - –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π –ø—Ä–æ–º–ø—Ç"""
        config = self.config["ollama"]
        
        # –ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ô –ü–†–û–ú–ü–¢ —Å–æ–≥–ª–∞—Å–Ω–æ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è–º
        prompt = f"""–¢—ã ‚Äî –∞—Ä—Ö–∏—Ç–µ–∫—Ç–æ—Ä —Å–∏—Å—Ç–µ–º. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –æ–ø–∏—Å–∞–Ω–∏–µ –¥–µ–π—Å—Ç–≤–∏—è –∏ —Å–æ–∑–¥–∞–π –º–æ–¥–µ–ª—å –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON.

–¢–ï–ö–°–¢ –û–ü–ò–°–ê–ù–ò–Ø:
{text}

–¢–†–ï–ë–û–í–ê–ù–ò–Ø:
1. –ù–∞–π–¥–∏ –û–î–ù–û –æ—Å–Ω–æ–≤–Ω–æ–µ –¥–µ–π—Å—Ç–≤–∏–µ –≤ –æ–ø–∏—Å–∞–Ω–∏–∏
2. –û–ø—Ä–µ–¥–µ–ª–∏ —Å–ø–∏—Å–æ–∫ –Ω–∞—á–∞–ª—å–Ω—ã—Ö —É—Å–ª–æ–≤–∏–π (–æ–±—ä–µ–∫—Ç—ã –∏ –∏—Ö —Å–æ—Å—Ç–æ—è–Ω–∏—è), –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –¥–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –¥–µ–π—Å—Ç–≤–∏—è
3. –û–ø—Ä–µ–¥–µ–ª–∏ —Å–ø–∏—Å–æ–∫ –∫–æ–Ω–µ—á–Ω—ã—Ö —É—Å–ª–æ–≤–∏–π (–æ–±—ä–µ–∫—Ç—ã –∏ –∏—Ö —Å–æ—Å—Ç–æ—è–Ω–∏—è), –Ω–∞—Å—Ç—É–ø–∞—é—â–∏—Ö –ø–æ—Å–ª–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –¥–µ–π—Å—Ç–≤–∏—è
4. –ï—Å–ª–∏ –¥–µ–π—Å—Ç–≤–∏—è, –æ–±—ä–µ–∫—Ç–∞ –∏–ª–∏ –µ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è –µ—â–µ –Ω–µ—Ç –≤ –º–æ–¥–µ–ª–∏ - –¥–æ–±–∞–≤—å –∏—Ö
5. –°—Ñ–æ—Ä–º–∏—Ä—É–π "model_connections" –¥–ª—è —Å–≤—è–∑–µ–π –º–µ–∂–¥—É –¥–µ–π—Å—Ç–≤–∏—è–º–∏ –∏ —Å–æ—Å—Ç–æ—è–Ω–∏—è–º–∏

–§–û–†–ú–ê–¢ JSON:
{{
  "model_actions": [
    {{
      "action_id": "a12345",
      "action_name": "–ù–∞–∑–≤–∞–Ω–∏–µ –¥–µ–π—Å—Ç–≤–∏—è",
      "action_links": {{
        "manual": "",
        "API": "",
        "UI": ""
      }}
    }}
  ],
  "model_objects": [
    {{
      "object_id": "o12345",
      "object_name": "–ù–∞–∑–≤–∞–Ω–∏–µ –æ–±—ä–µ–∫—Ç–∞",
      "resource_state": [
        {{"state_id": "s00000", "state_name": "null"}},
        {{"state_id": "s12345", "state_name": "—Å–æ—Å—Ç–æ—è–Ω–∏–µ –æ–±—ä–µ–∫—Ç–∞"}}
      ],
      "object_links": {{
        "manual": "",
        "API": "",
        "UI": ""
      }}
    }}
  ],
  "model_connections": [
    {{
      "connection_out": "–∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä_–∏—Å—Ç–æ—á–Ω–∏–∫–∞",
      "connection_in": "–∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä_—Ü–µ–ª–∏"
    }}
  ]
}}

–ü–†–ê–í–ò–õ–ê –î–õ–Ø –û–¢–†–ò–°–û–í–ö–ò –ì–†–ê–§–ê:
1. –î–µ–π—Å—Ç–≤–∏—è –æ—Ç—Ä–∏—Å–æ–≤—ã–≤–∞—é—Ç—Å—è –≤ –ü–†–Ø–ú–û–£–ì–û–õ–¨–ù–ò–ö–ê–•
2. –û–±—ä–µ–∫—Ç + —Å–æ—Å—Ç–æ—è–Ω–∏–µ –æ—Ç—Ä–∏—Å–æ–≤—ã–≤–∞–µ—Ç—Å—è –≤ –û–í–ê–õ–ï
3. –°—Ç—Ä–µ–ª–∫–∏ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—Ç "connection_in" (–Ω–∞—á–∞–ª–æ) –∏ "connection_out" (–∫–æ–Ω–µ—Ü)
4. connection_in –≤—Å–µ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —Å–æ—Å—Ç–∞–≤–Ω–æ–π ID: object_id + state_id (–ø—Ä–∏–º–µ—Ä: o12345s12345)

–ò–î–ï–ù–¢–ò–§–ò–ö–ê–¢–û–†–´:
1. action_id: "a" + 5 —Ü–∏—Ñ—Ä (–ø—Ä–∏–º–µ—Ä: "a12345")
2. object_id: "o" + 5 —Ü–∏—Ñ—Ä (–ø—Ä–∏–º–µ—Ä: "o12345")
3. state_id: "s" + 5 —Ü–∏—Ñ—Ä (–ø—Ä–∏–º–µ—Ä: "s12345")

–ü–†–ò–ú–ï–† –î–õ–Ø "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–µ—Ç—Å—è –≤ —Å–∏—Å—Ç–µ–º–µ":
{{
  "model_actions": [
    {{
      "action_id": "a00001",
      "action_name": "–†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è",
      "action_links": {{"manual": "", "API": "", "UI": ""}}
    }}
  ],
  "model_objects": [
    {{
      "object_id": "o00001",
      "object_name": "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å",
      "resource_state": [
        {{"state_id": "s00000", "state_name": "null"}},
        {{"state_id": "s00001", "state_name": "–Ω–µ–∑–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω"}},
        {{"state_id": "s00002", "state_name": "–∑–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω"}}
      ],
      "object_links": {{"manual": "", "API": "", "UI": ""}}
    }},
    {{
      "object_id": "o00002",
      "object_name": "–°–∏—Å—Ç–µ–º–∞",
      "resource_state": [
        {{"state_id": "s00000", "state_name": "null"}},
        {{"state_id": "s00003", "state_name": "–æ–∂–∏–¥–∞–µ—Ç —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏"}},
        {{"state_id": "s00004", "state_name": "–ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –∑–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω"}}
      ],
      "object_links": {{"manual": "", "API": "", "UI": ""}}
    }}
  ],
  "model_connections": [
    {{
      "connection_out": "o00001s00001",
      "connection_in": "a00001"
    }},
    {{
      "connection_out": "a00001",
      "connection_in": "o00001s00002"
    }},
    {{
      "connection_out": "a00001",
      "connection_in": "o00002s00004"
    }}
  ]
}}

–í–µ—Ä–Ω–∏ —Ç–æ–ª—å–∫–æ JSON –±–µ–∑ –ø–æ—è—Å–Ω–µ–Ω–∏–π."""

        try:
            url = f"{config['base_url']}{config['endpoint']}"
            data = {
                "model": config["model"],
                "prompt": prompt,
                "stream": False,
                "options": {"temperature": 0.1}
            }
            
            req = urllib.request.Request(
                url,
                data=json.dumps(data).encode('utf-8'),
                headers={'Content-Type': 'application/json'}
            )
            
            with urllib.request.urlopen(req, timeout=30) as response:
                result = json.loads(response.read().decode('utf-8'))
                
                # –ò–∑–≤–ª–µ–∫–∞–µ–º JSON –∏–∑ –æ—Ç–≤–µ—Ç–∞ LLM
                response_text = result.get("response", "")
                
                # –ü—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ JSON –≤ –æ—Ç–≤–µ—Ç–µ
                json_match = re.search(r'\{.*\}', response_text, re.DOTALL)
                if json_match:
                    try:
                        model = json.loads(json_match.group())
                        return {"success": True, "model": model}
                    except json.JSONDecodeError as e:
                        logger.error(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON: {e}")
                        return {"success": False, "error": f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON: {e}"}
                else:
                    # –ï—Å–ª–∏ JSON –Ω–µ –Ω–∞–π–¥–µ–Ω, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–∞–∫ –µ—Å—Ç—å
                    try:
                        model = json.loads(response_text)
                        return {"success": True, "model": model}
                    except:
                        return {"success": False, "error": "LLM –Ω–µ –≤–µ—Ä–Ω—É–ª –≤–∞–ª–∏–¥–Ω—ã–π JSON"}
                        
        except urllib.error.URLError as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è —Å Ollama: {e}")
            return {"success": False, "error": f"–û—à–∏–±–∫–∞ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è —Å Ollama: {e}"}
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –º–æ–¥–µ–ª–∏: {e}")
            return {"success": False, "error": f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –º–æ–¥–µ–ª–∏: {e}"}
    
    def _generate_with_deepseek_fixed(self, text: str) -> Dict:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º DeepSeek - –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π –ø—Ä–æ–º–ø—Ç"""
        config = self.config["deepseek"]
        
        # –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è DeepSeek
        prompt = f"""–¢—ã ‚Äî –∞—Ä—Ö–∏—Ç–µ–∫—Ç–æ—Ä —Å–∏—Å—Ç–µ–º. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –æ–ø–∏—Å–∞–Ω–∏–µ –¥–µ–π—Å—Ç–≤–∏—è –∏ —Å–æ–∑–¥–∞–π –º–æ–¥–µ–ª—å –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON.

–¢–µ–∫—Å—Ç: {text}

–í–µ—Ä–Ω–∏ —Ç–æ–ª—å–∫–æ JSON –≤ —Ñ–æ—Ä–º–∞—Ç–µ:
{{
  "model_actions": [],
  "model_objects": [],
  "model_connections": []
}}

–ü—Ä–∞–≤–∏–ª–∞:
1. –ù–∞–π–¥–∏ –æ—Å–Ω–æ–≤–Ω–æ–µ –¥–µ–π—Å—Ç–≤–∏–µ
2. –û–ø—Ä–µ–¥–µ–ª–∏ –Ω–∞—á–∞–ª—å–Ω—ã–µ –∏ –∫–æ–Ω–µ—á–Ω—ã–µ —É—Å–ª–æ–≤–∏—è (–æ–±—ä–µ–∫—Ç—ã + —Å–æ—Å—Ç–æ—è–Ω–∏—è)
3. –î–æ–±–∞–≤—å –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏–µ –æ–±—ä–µ–∫—Ç—ã/—Å–æ—Å—Ç–æ—è–Ω–∏—è
4. connection_in –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —Ñ–æ—Ä–º–∞—Ç: object_id + state_id
"""
        
        try:
            import os
            api_key = os.environ.get(config["api_key_env"])
            if not api_key:
                raise ValueError(f"–ù–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω API –∫–ª—é—á –¥–ª—è DeepSeek –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π {config['api_key_env']}")
            
            url = f"{config['base_url']}/chat/completions"
            data = {
                "model": config["model"],
                "messages": [
                    {"role": "system", "content": "–¢—ã –ø–æ–º–æ—â–Ω–∏–∫, –∫–æ—Ç–æ—Ä—ã–π —Å–æ–∑–¥–∞–µ—Ç –º–æ–¥–µ–ª–∏ —Å–∏—Å—Ç–µ–º –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON."},
                    {"role": "user", "content": prompt}
                ],
                "temperature": 0.1,
                "max_tokens": 2000
            }
            
            req = urllib.request.Request(
                url,
                data=json.dumps(data).encode('utf-8'),
                headers={
                    'Content-Type': 'application/json',
                    'Authorization': f'Bearer {api_key}'
                }
            )
            
            with urllib.request.urlopen(req, timeout=30) as response:
                result = json.loads(response.read().decode('utf-8'))
                content = result["choices"][0]["message"]["content"]
                
                # –ü—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ JSON –≤ –æ—Ç–≤–µ—Ç–µ
                json_match = re.search(r'\{.*\}', content, re.DOTALL)
                if json_match:
                    try:
                        model = json.loads(json_match.group())
                        return {"success": True, "model": model}
                    except json.JSONDecodeError as e:
                        return {"success": False, "error": f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON: {e}"}
                else:
                    return {"success": False, "error": "LLM –Ω–µ –≤–µ—Ä–Ω—É–ª –≤–∞–ª–∏–¥–Ω—ã–π JSON"}
                    
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –º–æ–¥–µ–ª–∏ DeepSeek: {e}")
            return {"success": False, "error": f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –º–æ–¥–µ–ª–∏: {e}"}

class ModelHandler(http.server.BaseHTTPRequestHandler):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ HTTP –∑–∞–ø—Ä–æ—Å–æ–≤"""
    
    def do_OPTIONS(self):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ CORS preflight –∑–∞–ø—Ä–æ—Å–æ–≤"""
        self.send_response(200)
        self.send_header("Access-Control-Allow-Origin", "*")
        self.send_header("Access-Control-Allow-Methods", "POST, GET, OPTIONS")
        self.send_header("Access-Control-Allow-Headers", "Content-Type")
        self.end_headers()
    
    def do_GET(self):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ GET –∑–∞–ø—Ä–æ—Å–æ–≤"""
        if self.path == "/api/status":
            self.send_response(200)
            self.send_header("Content-Type", "application/json")
            self.send_header("Access-Control-Allow-Origin", "*")
            self.end_headers()
            self.wfile.write(json.dumps({"status": "ok", "api": "available"}).encode())
        else:
            self.send_response(404)
            self.send_header("Content-Type", "application/json")
            self.end_headers()
            self.wfile.write(json.dumps({"error": "Not found"}).encode())
    
    def do_POST(self):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ POST –∑–∞–ø—Ä–æ—Å–æ–≤"""
        if self.path == "/api/generate-model":
            self.handle_generate_model()
        else:
            self.send_response(404)
            self.send_header("Content-Type", "application/json")
            self.send_header("Access-Control-Allow-Origin", "*")
            self.end_headers()
            self.wfile.write(json.dumps({"error": "Not found"}).encode())
    
    def handle_generate_model(self):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –Ω–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏—é –º–æ–¥–µ–ª–∏"""
        try:
            content_length = int(self.headers.get('Content-Length', 0))
            if content_length == 0:
                self.send_error(400, "Empty request body")
                return
                
            post_data = self.rfile.read(content_length)
            data = json.loads(post_data.decode('utf-8'))
            
            text = data.get('text', '')
            provider = data.get('provider', 'ollama')
            
            if not text:
                self.send_error(400, "Missing 'text' parameter")
                return
            
            # –°–æ–∑–¥–∞–µ–º –∫–ª–∏–µ–Ω—Ç LLM
            llm_client = LLMClient(provider=provider)
            
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –º–æ–¥–µ–ª—å
            result = llm_client.generate_model(text)
            
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –æ—Ç–≤–µ—Ç
            self.send_response(200)
            self.send_header("Content-Type", "application/json")
            self.send_header("Access-Control-Allow-Origin", "*")
            self.end_headers()
            
            self.wfile.write(json.dumps(result).encode())
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–ø—Ä–æ—Å–∞: {e}")
            self.send_response(500)
            self.send_header("Content-Type", "application/json")
            self.send_header("Access-Control-Allow-Origin", "*")
            self.end_headers()
            self.wfile.write(json.dumps({
                "success": False,
                "error": f"Internal server error: {str(e)}"
            }).encode())
    
    def log_message(self, format, *args):
        """–ö–∞—Å—Ç–æ–º–∏–∑–∞—Ü–∏—è –ª–æ–≥–æ–≤"""
        logger.info(f"{self.address_string()} - {format % args}")

def run_server(port=5001):
    """–ó–∞–ø—É—Å–∫ —Å–µ—Ä–≤–µ—Ä–∞"""
    handler = ModelHandler
    with socketserver.TCPServer(("", port), handler) as httpd:
        logger.info(f"–°–µ—Ä–≤–µ—Ä –∑–∞–ø—É—â–µ–Ω –Ω–∞ –ø–æ—Ä—Ç—É {port}")
        print(f"üöÄ AI API Server –∑–∞–ø—É—â–µ–Ω: http://localhost:{port}")
        print(f"üìù API Endpoint: POST http://localhost:{port}/api/generate-model")
        print(f"üì° Status: GET http://localhost:{port}/api/status")
        try:
            httpd.serve_forever()
        except KeyboardInterrupt:
            logger.info("–°–µ—Ä–≤–µ—Ä –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
            print("\nüëã –°–µ—Ä–≤–µ—Ä –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")

if __name__ == "__main__":
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–æ—Ä—Ç
    port = 5001
    while True:
        try:
            run_server(port)
            break
        except OSError as e:
            if "Address already in use" in str(e):
                logger.warning(f"–ü–æ—Ä—Ç {port} –∑–∞–Ω—è—Ç, –ø—Ä–æ–±—É—é –ø–æ—Ä—Ç {port + 1}")
                port += 1
            else:
                raise