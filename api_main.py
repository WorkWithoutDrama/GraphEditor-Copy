#!/usr/bin/env python3
"""
–°–ê–ú–´–ô –ü–†–û–°–¢–û–ô API –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –≤—ã–≤–æ–¥–∞ –ª–æ–≥–æ–≤
"""

import http.server
import socketserver
import json
import sys
import datetime

# –ü–†–ò–ù–£–î–ò–¢–ï–õ–¨–ù–û –û–¢–ö–õ–Æ–ß–ê–ï–ú –í–°–Æ –ë–£–§–ï–†–ò–ó–ê–¶–ò–Æ
# 1. –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é –æ–∫—Ä—É–∂–µ–Ω–∏—è
import os
os.environ['PYTHONUNBUFFERED'] = '1'

# 2. –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ —Å–±—Ä–∞—Å—ã–≤–∞–µ–º –±—É—Ñ–µ—Ä sys.stdout
sys.stdout = os.fdopen(sys.stdout.fileno(), 'w', 1)

print("=" * 60)
print("üöÄ –¢–ï–°–¢–û–í–´–ô API - –ì–ê–†–ê–ù–¢–ò–†–û–í–ê–ù–ù–´–ô –í–´–í–û–î –õ–û–ì–û–í")
print("=" * 60)
print("–≠—Ç–æ —Å–æ–æ–±—â–µ–Ω–∏–µ –î–û–õ–ñ–ù–û –±—ã—Ç—å –≤–∏–¥–Ω–æ —Å—Ä–∞–∑—É!")
sys.stdout.flush()

class TestAPIHandler(http.server.BaseHTTPRequestHandler):
    
    def log_message(self, format, *args):
        """–ö–∞—Å—Ç–æ–º–∏–∑–∞—Ü–∏—è –ª–æ–≥–æ–≤ - –≤—ã–≤–æ–¥–∏–º –í–°–ï–ì–î–ê"""
        message = f"{self.address_string()} - {format % args}"
        print(f"üîπ {message}")
        sys.stdout.flush()
    
    def do_GET(self):
        if self.path == "/api/health":
            print("üì° –û–ë–†–ê–ë–û–¢–ö–ê GET /api/health")
            sys.stdout.flush()
            
            self.send_response(200)
            self.send_header("Content-Type", "application/json")
            self.send_header("Access-Control-Allow-Origin", "*")
            self.end_headers()
            self.wfile.write(json.dumps({"status": "ok", "api": "test"}).encode())
            sys.stdout.flush()
        else:
            self.send_response(404)
            self.send_header("Content-Type", "application/json")
            self.end_headers()
            self.wfile.write(json.dumps({"error": "Not found"}).encode())
    
    def do_POST(self):
        if self.path == "/api/generate-model":
            print("üì• –ü–û–õ–£–ß–ï–ù POST –ó–ê–ü–†–û–° /api/generate-model")
            sys.stdout.flush()
            
            try:
                content_length = int(self.headers.get('Content-Length', 0))
                post_data = self.rfile.read(content_length)
                data = json.loads(post_data.decode('utf-8'))
                text = data.get('text', '')
                
                print(f"üìÑ –¢–µ–∫—Å—Ç –∑–∞–ø—Ä–æ—Å–∞: {text[:100]}...")
                print(f"üìè –î–ª–∏–Ω–∞: {len(text)} —Å–∏–º–≤–æ–ª–æ–≤")
                
                # –ü–æ–ª—É—á–∞–µ–º –∏–º—è –º–æ–¥–µ–ª–∏ –∏–∑ –∑–∞–ø—Ä–æ—Å–∞
                model_name = data.get('model_name', 'unnamed_model')
                print(f"üè∑Ô∏è  –ò–º—è –º–æ–¥–µ–ª–∏: {model_name}")
                sys.stdout.flush()
                
                # –®–∞–≥ 1: –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å LLM
                print("üîç –ü–†–û–í–ï–†–Ø–Æ –î–û–°–¢–£–ü–ù–û–°–¢–¨ LLM (Ollama)...")
                sys.stdout.flush()
                
                llm_available, llm_status = self.check_llm_availability()
                
                if not llm_available:
                    print(f"‚ùå LLM –ù–ï–î–û–°–¢–£–ü–ï–ù: {llm_status}")
                    print("‚ö†Ô∏è  –ò—Å–ø–æ–ª—å–∑—É—é —É–ø—Ä–æ—â–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Ç–µ–∫—Å—Ç–∞")
                    sys.stdout.flush()
                    
                    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–æ—Ç–æ–∫–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑ –µ—Å–ª–∏ LLM –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω
                    model = self.stream_text_analysis(text, model_name)
                else:
                    print(f"‚úÖ LLM –î–û–°–¢–£–ü–ï–ù: {llm_status}")
                    print("üîÑ –ó–ê–ü–£–°–ö–ê–Æ LLM –î–õ–Ø –ê–ù–ê–õ–ò–ó–ê –¢–ó...")
                    sys.stdout.flush()
                    
                    # –®–∞–≥ 2: –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –ø—Ä–æ–º–ø—Ç –¥–ª—è LLM
                    prompt = self.generate_llm_prompt(text)
                    print(f"üìù –ü—Ä–æ–º–ø—Ç –¥–ª—è LLM (–ø–µ—Ä–≤—ã–µ 300 —Å–∏–º–≤–æ–ª–æ–≤): {prompt[:300]}...")
                    sys.stdout.flush()
                    
                    # –®–∞–≥ 3: –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å –∫ LLM
                    print("ü§ñ –û–¢–ü–†–ê–í–õ–Ø–Æ –ó–ê–ü–†–û–° –ö LLM...")
                    sys.stdout.flush()
                    
                    llm_response = self.query_llm(prompt)
                    
                    if llm_response["success"]:
                        print("‚úÖ LLM –û–¢–í–ï–¢–ò–õ –£–°–ü–ï–®–ù–û!")
                        print(f"üìÑ –û—Ç–≤–µ—Ç LLM (–ø–µ—Ä–≤—ã–µ 300 —Å–∏–º–≤–æ–ª–æ–≤): {llm_response['response'][:300]}...")
                        sys.stdout.flush()
                        
                        # –®–∞–≥ 4: –ü–∞—Ä—Å–∏–º –æ—Ç–≤–µ—Ç LLM
                        model = self.parse_llm_response(llm_response["response"])
                        
                        if not model:
                            print("‚ùå –ù–ï –£–î–ê–õ–û–°–¨ –†–ê–°–ü–ê–†–°–ò–¢–¨ –û–¢–í–ï–¢ LL–ú")
                            print("‚ö†Ô∏è  –ò—Å–ø–æ–ª—å–∑—É—é —É–ø—Ä–æ—â–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑")
                            sys.stdout.flush()
                            model = self.stream_text_analysis(text, model_name)
                        else:
                            print("üéØ –ú–û–î–ï–õ–¨ –°–ì–ï–ù–ï–†–ò–†–û–í–ê–ù–ê LLM!")
                            sys.stdout.flush()
                    else:
                        print(f"‚ùå –û–®–ò–ë–ö–ê LLM: {llm_response['error']}")
                        print("‚ö†Ô∏è  –ò—Å–ø–æ–ª—å–∑—É—é —É–ø—Ä–æ—â–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑")
                        sys.stdout.flush()
                        model = self.stream_text_analysis(text, model_name)
                
                # –í–´–í–û–î–ò–ú JSON - –ü–û–°–¢–†–û–ß–ù–û –ò –° –ü–†–ò–ù–£–î–ò–¢–ï–õ–¨–ù–´–ú FLUSH
                print("üéØ –°–ì–ï–ù–ï–†–ò–†–û–í–ê–ù–ù–ê–Ø –ú–û–î–ï–õ–¨:")
                sys.stdout.flush()
                
                json_str = json.dumps(model, ensure_ascii=False, indent=2)
                for line in json_str.split('\n'):
                    print(line)
                    sys.stdout.flush()
                
                print("üìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê:")
                print(f"‚Ä¢ –î–µ–π—Å—Ç–≤–∏–π: {len(model.get('model_actions', []))}")
                print(f"‚Ä¢ –û–±—ä–µ–∫—Ç–æ–≤: {len(model.get('model_objects', []))}")
                print(f"‚Ä¢ –°–≤—è–∑–µ–π: {len(model.get('model_connections', []))}")
                sys.stdout.flush()
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å –≤ —Ñ–∞–π–ª
                saved_filename = self.save_model_to_file(model, model_name)
                if saved_filename:
                    print(f"üíæ –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {saved_filename}")
                    response = {"success": True, "model": model, "saved_to": saved_filename}
                else:
                    print("‚ö†Ô∏è  –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –º–æ–¥–µ–ª—å")
                    response = {"success": True, "model": model, "save_error": "–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –º–æ–¥–µ–ª—å"}
                self.send_response(200)
                self.send_header("Content-Type", "application/json")
                self.send_header("Access-Control-Allow-Origin", "*")
                self.end_headers()
                self.wfile.write(json.dumps(response, ensure_ascii=False).encode())
                
                print("‚úÖ –û–¢–í–ï–¢ –û–¢–ü–†–ê–í–õ–ï–ù")
                sys.stdout.flush()
                
            except Exception as e:
                print(f"‚ùå –û–®–ò–ë–ö–ê: {e}")
                sys.stdout.flush()
                self.send_response(500)
                self.send_header("Content-Type", "application/json")
                self.end_headers()
                self.wfile.write(json.dumps({"success": False, "error": str(e)}).encode())
                
                # –í–´–í–û–î–ò–ú JSON - –ü–û–°–¢–†–û–ß–ù–û –ò –° –ü–†–ò–ù–£–î–ò–¢–ï–õ–¨–ù–´–ú FLUSH
                print("üéØ –°–ì–ï–ù–ï–†–ò–†–û–í–ê–ù–ù–ê–Ø –ú–û–î–ï–õ–¨:")
                sys.stdout.flush()
                
                json_str = json.dumps(model, ensure_ascii=False, indent=2)
                for line in json_str.split('\n'):
                    print(line)
                    sys.stdout.flush()
                
                print("üìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê:")
                print(f"‚Ä¢ –î–µ–π—Å—Ç–≤–∏–π: {len(model.get('model_actions', []))}")
                print(f"‚Ä¢ –û–±—ä–µ–∫—Ç–æ–≤: {len(model.get('model_objects', []))}")
                print(f"‚Ä¢ –°–≤—è–∑–µ–π: {len(model.get('model_connections', []))}")
                sys.stdout.flush()
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å –≤ —Ñ–∞–π–ª
                saved_filename = self.save_model_to_file(model, model_name)
                if saved_filename:
                    print(f"üíæ –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {saved_filename}")
                    response = {"success": True, "model": model, "saved_to": saved_filename}
                else:
                    print("‚ö†Ô∏è  –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –º–æ–¥–µ–ª—å")
                    response = {"success": True, "model": model, "save_error": "–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –º–æ–¥–µ–ª—å"}
                self.send_response(200)
                self.send_header("Content-Type", "application/json")
                self.send_header("Access-Control-Allow-Origin", "*")
                self.end_headers()
                self.wfile.write(json.dumps(response, ensure_ascii=False).encode())
                
                print("‚úÖ –û–¢–í–ï–¢ –û–¢–ü–†–ê–í–õ–ï–ù")
                sys.stdout.flush()
                
            except Exception as e:
                print(f"‚ùå –û–®–ò–ë–ö–ê: {e}")
                sys.stdout.flush()
                self.send_response(500)
                self.send_header("Content-Type", "application/json")
                self.end_headers()
                self.wfile.write(json.dumps({"success": False, "error": str(e)}).encode())
        else:
            self.send_response(404)
            self.send_header("Content-Type", "application/json")
            self.end_headers()
            self.wfile.write(json.dumps({"error": "Not found"}).encode())
    
    def check_llm_availability(self):
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å LLM (Ollama)"""
        try:
            import subprocess
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –∑–∞–ø—É—â–µ–Ω –ª–∏ —Å–µ—Ä–≤–µ—Ä Ollama
            result = subprocess.run(
                ["curl", "-s", "http://localhost:11434/api/tags"],
                capture_output=True,
                text=True,
                timeout=5
            )
            
            if result.returncode == 0:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –º–æ–¥–µ–ª–∏ llama3.2
                if "llama3.2" in result.stdout:
                    return True, "Ollama —Å –º–æ–¥–µ–ª—å—é llama3.2"
                else:
                    return False, "–ú–æ–¥–µ–ª—å llama3.2 –Ω–µ –Ω–∞–π–¥–µ–Ω–∞"
            else:
                return False, "–°–µ—Ä–≤–µ—Ä Ollama –Ω–µ –∑–∞–ø—É—â–µ–Ω"
                
        except subprocess.TimeoutExpired:
            return False, "–¢–∞–π–º–∞—É—Ç –ø—Ä–æ–≤–µ—Ä–∫–∏"
        except Exception as e:
            return False, f"–û—à–∏–±–∫–∞: {str(e)}"
    
    def generate_llm_prompt(self, text):
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –ø—Ä–æ–º–ø—Ç –¥–ª—è LLM"""
        prompt = """–¢—ã - –∞–Ω–∞–ª–∏—Ç–∏–∫ –ø—Ä–æ—Ü–µ—Å—Å–æ–≤. –¢–≤–æ—è –∑–∞–¥–∞—á–∞ - –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–µ –∑–∞–¥–∞–Ω–∏–µ –∏ —Å–æ–∑–¥–∞—Ç—å —Ñ–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—É—é –º–æ–¥–µ–ª—å –ø—Ä–æ—Ü–µ—Å—Å–æ–≤.

–ê–ù–ê–õ–ò–ó–ò–†–£–ô —Å–ª–µ–¥—É—é—â–µ–µ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–µ –∑–∞–¥–∞–Ω–∏–µ:

"""
        prompt += text
        prompt += """

–ò–ù–°–¢–†–£–ö–¶–ò–ò –ü–û –ê–ù–ê–õ–ò–ó–£:

1. –ò–î–ï–ù–¢–ò–§–ò–¶–ò–†–£–ô –î–ï–ô–°–¢–í–ò–Ø:
   - –ù–∞–π–¥–∏—Ç–µ –≤—Å–µ –∫–ª—é—á–µ–≤—ã–µ –¥–µ–π—Å—Ç–≤–∏—è/–ø—Ä–æ—Ü–µ—Å—Å—ã –≤ –¢–ó
   - –ö–∞–∂–¥–æ–µ –¥–µ–π—Å—Ç–≤–∏–µ –¥–æ–ª–∂–Ω–æ –∏–º–µ—Ç—å —É–Ω–∏–∫–∞–ª—å–Ω—ã–π ID –≤ —Ñ–æ—Ä–º–∞—Ç–µ "a" + 5 —Ü–∏—Ñ—Ä (–Ω–∞–ø—Ä–∏–º–µ—Ä: a00001)
   - –ù–∞–∑–≤–∞–Ω–∏–µ –¥–µ–π—Å—Ç–≤–∏—è –¥–æ–ª–∂–Ω–æ –∫—Ä–∞—Ç–∫–æ –æ–ø–∏—Å—ã–≤–∞—Ç—å –ø—Ä–æ—Ü–µ—Å—Å

2. –ò–î–ï–ù–¢–ò–§–ò–¶–ò–†–£–ô –û–ë–™–ï–ö–¢–´ –ò –ò–• –°–û–°–¢–û–Ø–ù–ò–Ø:
   - –ù–∞–π–¥–∏—Ç–µ –≤—Å–µ –æ–±—ä–µ–∫—Ç—ã —Å–∏—Å—Ç–µ–º—ã (—Å—É—â–Ω–æ—Å—Ç–∏, —Ä–µ—Å—É—Ä—Å—ã)
   - –î–ª—è –∫–∞–∂–¥–æ–≥–æ –æ–±—ä–µ–∫—Ç–∞ –æ–ø—Ä–µ–¥–µ–ª–∏—Ç–µ –≤–æ–∑–º–æ–∂–Ω—ã–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è
   - –ö–∞–∂–¥—ã–π –æ–±—ä–µ–∫—Ç –¥–æ–ª–∂–µ–Ω –∏–º–µ—Ç—å —É–Ω–∏–∫–∞–ª—å–Ω—ã–π ID –≤ —Ñ–æ—Ä–º–∞—Ç–µ "o" + 5 —Ü–∏—Ñ—Ä (–Ω–∞–ø—Ä–∏–º–µ—Ä: o00001)
   - –ö–∞–∂–¥–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –¥–æ–ª–∂–Ω–æ –∏–º–µ—Ç—å —É–Ω–∏–∫–∞–ª—å–Ω—ã–π ID –≤ —Ñ–æ—Ä–º–∞—Ç–µ "s" + 5 —Ü–∏—Ñ—Ä (–Ω–∞–ø—Ä–∏–º–µ—Ä: s00001)
   - –û–±—ä–µ–∫—Ç+—Å–æ—Å—Ç–æ—è–Ω–∏–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç—Å—è –∫–∞–∫ –µ–¥–∏–Ω–æ–µ —Ü–µ–ª–æ–µ (–Ω–∞–ø—Ä–∏–º–µ—Ä: "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å: –Ω–µ–∞–∫—Ç–∏–≤–µ–Ω")

3. –û–ü–†–ï–î–ï–õ–ò –°–í–Ø–ó–ò:
   - –î–ª—è –∫–∞–∂–¥–æ–≥–æ –¥–µ–π—Å—Ç–≤–∏—è –Ω–∞–π–¥–∏—Ç–µ:
     * –ö–∞–∫–∏–µ –æ–±—ä–µ–∫—Ç—ã –≤ –∫–∞–∫–∏—Ö —Å–æ—Å—Ç–æ—è–Ω–∏—è—Ö –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã –¥–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –¥–µ–π—Å—Ç–≤–∏—è (–Ω–∞—á–∞–ª—å–Ω—ã–µ —É—Å–ª–æ–≤–∏—è)
     * –í –∫–∞–∫–∏–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è –ø–µ—Ä–µ—Ö–æ–¥—è—Ç –æ–±—ä–µ–∫—Ç—ã –ø–æ—Å–ª–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –¥–µ–π—Å—Ç–≤–∏—è (–∫–æ–Ω–µ—á–Ω—ã–µ —É—Å–ª–æ–≤–∏—è)
   - –°–≤—è–∑–∏ –∏–º–µ—é—Ç —Ñ–æ—Ä–º–∞—Ç: "–æ–±—ä–µ–∫—Ç+—Å–æ—Å—Ç–æ—è–Ω–∏–µ" ‚Üí "–¥–µ–π—Å—Ç–≤–∏–µ" ‚Üí "–æ–±—ä–µ–∫—Ç+—Å–æ—Å—Ç–æ—è–Ω–∏–µ"
   - connection_out - ID –∏—Å—Ç–æ—á–Ω–∏–∫–∞ (–Ω–∞—á–∞–ª—å–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –∏–ª–∏ –¥–µ–π—Å—Ç–≤–∏–µ)
   - connection_in - ID —Ü–µ–ª–∏ (–¥–µ–π—Å—Ç–≤–∏–µ –∏–ª–∏ –∫–æ–Ω–µ—á–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ)

4. –§–û–†–ú–ê–¢ –í–´–í–û–î–ê:
   - –í—ã–≤–µ–¥–∏ –¢–û–õ–¨–ö–û –≤–∞–ª–∏–¥–Ω—ã–π JSON –±–µ–∑ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞
   - JSON –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å —Ç—Ä–∏ –º–∞—Å—Å–∏–≤–∞: model_actions, model_objects, model_connections
   - –í—Å–µ ID –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –≤ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ
   - –ï—Å–ª–∏ –æ–±—ä–µ–∫—Ç–∞/–¥–µ–π—Å—Ç–≤–∏—è/—Å–æ—Å—Ç–æ—è–Ω–∏—è –Ω–µ—Ç –≤ –º–æ–¥–µ–ª–∏ - –¥–æ–±–∞–≤—å –µ–≥–æ

5. –ü–†–ò–ú–ï–† –î–õ–Ø –¢–ó "–†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è":
   - –î–µ–π—Å—Ç–≤–∏–µ: "–†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è" (a00001)
   - –û–±—ä–µ–∫—Ç: "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å" (o00001) —Å —Å–æ—Å—Ç–æ—è–Ω–∏—è–º–∏: "–Ω–µ–∑–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω" (s00001), "–∑–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω" (s00002)
   - –°–≤—è–∑—å: o00001s00001 ‚Üí a00001 ‚Üí o00001s00002

–í–ï–†–ù–ò –¢–û–õ–¨–ö–û JSON –û–¢–í–ï–¢:"""
        
        return prompt
    
    def query_llm(self, prompt):
        """–û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –∑–∞–ø—Ä–æ—Å –∫ LLM (Ollama)"""
        try:
            import subprocess
            import json as json_module
            
            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –∑–∞–ø—Ä–æ—Å –∫ Ollama API
            request_data = {
                "model": "llama3.2",
                "prompt": prompt,
                "stream": False,
                "options": {
                    "temperature": 0.7,
                    "num_predict": 2000
                }
            }
            
            # –í—ã–ø–æ–ª–Ω—è–µ–º –∑–∞–ø—Ä–æ—Å —á–µ—Ä–µ–∑ curl
            curl_command = [
                "curl", "-s",
                "-X", "POST",
                "http://localhost:11434/api/generate",
                "-H", "Content-Type: application/json",
                "-d", json_module.dumps(request_data)
            ]
            
            result = subprocess.run(
                curl_command,
                capture_output=True,
                text=True,
                timeout=30  # 30 —Å–µ–∫—É–Ω–¥ —Ç–∞–π–º–∞—É—Ç –¥–ª—è LLM
            )
            
            if result.returncode == 0:
                try:
                    response_data = json_module.loads(result.stdout)
                    if "response" in response_data:
                        return {
                            "success": True,
                            "response": response_data["response"]
                        }
                    else:
                        return {
                            "success": False,
                            "error": "–ù–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞ LLM"
                        }
                except json_module.JSONDecodeError:
                    return {
                        "success": False,
                        "error": "–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å JSON –æ—Ç LLM"
                    }
            else:
                return {
                    "success": False,
                    "error": f"–û—à–∏–±–∫–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞–ø—Ä–æ—Å–∞: {result.stderr}"
                }
                
        except subprocess.TimeoutExpired:
            return {
                "success": False,
                "error": "–¢–∞–π–º–∞—É—Ç –∑–∞–ø—Ä–æ—Å–∞ –∫ LLM"
            }
        except Exception as e:
            return {
                "success": False,
                "error": f"–û—à–∏–±–∫–∞: {str(e)}"
            }
    
    def parse_llm_response(self, response):
        """–ü–∞—Ä—Å–∏—Ç –∏ –≤–∞–ª–∏–¥–∏—Ä—É–µ—Ç –æ—Ç–≤–µ—Ç LLM, –ø—Ä–µ–æ–±—Ä–∞–∑—É—è –≤ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç"""
        try:
            # –ò—â–µ–º JSON –≤ –æ—Ç–≤–µ—Ç–µ
            json_start = response.find('{')
            json_end = response.rfind('}') + 1
            
            if json_start == -1 or json_end == 0:
                print("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω JSON –≤ –æ—Ç–≤–µ—Ç–µ LLM")
                print(f"–û—Ç–≤–µ—Ç: {response[:500]}...")
                return None
            
            json_str = response[json_start:json_end]
            llm_model = json.loads(json_str)
            
            print(f"üîç –ü–∞—Ä—Å–∏–Ω–≥ –æ—Ç–≤–µ—Ç–∞ LLM: –Ω–∞–π–¥–µ–Ω–æ {len(llm_model.get('model_actions', []))} –¥–µ–π—Å—Ç–≤–∏–π")
            
            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Ñ–æ—Ä–º–∞—Ç LLM –≤ –Ω–∞—à —Ñ–æ—Ä–º–∞—Ç
            model = self.convert_llm_format(llm_model)
            
            # –ë–∞–∑–æ–≤–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è
            if not all(key in model for key in ["model_actions", "model_objects", "model_connections"]):
                print(f"‚ùå –ù–µ–ø–æ–ª–Ω–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø–æ—Å–ª–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è: {list(model.keys())}")
                return None
            
            print(f"‚úÖ JSON –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω: {len(model['model_actions'])} –¥–µ–π—Å—Ç–≤–∏–π, {len(model['model_objects'])} –æ–±—ä–µ–∫—Ç–æ–≤, {len(model['model_connections'])} —Å–≤—è–∑–µ–π")
            
            return model
            
        except json.JSONDecodeError as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON: {e}")
            print(f"–û—Ç–≤–µ—Ç: {response[:500]}...")
            return None
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ: {e}")
            import traceback
            traceback.print_exc()
            return None
    
    def convert_llm_format(self, llm_model):
        """–ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç —Ñ–æ—Ä–º–∞—Ç LLM –≤ –Ω–∞—à —Ñ–æ—Ä–º–∞—Ç"""
        model = {
            "model_actions": [],
            "model_objects": [],
            "model_connections": []
        }
        
        # 1. –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –¥–µ–π—Å—Ç–≤–∏—è
        if "model_actions" in llm_model:
            for i, action in enumerate(llm_model["model_actions"]):
                # LLM –º–æ–∂–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ä–∞–∑–Ω—ã–µ –∫–ª—é—á–∏
                action_id = action.get("id") or action.get("action_id") or f"a{i+1:05d}"
                action_name = action.get("name") or action.get("action_name") or f"–î–µ–π—Å—Ç–≤–∏–µ {i+1}"
                
                # –ï—Å–ª–∏ ID –Ω–µ –≤ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ, –∏—Å–ø—Ä–∞–≤–ª—è–µ–º
                if not action_id.startswith('a'):
                    action_id = f"a{i+1:05d}"
                
                model["model_actions"].append({
                    "action_id": action_id,
                    "action_name": action_name,
                    "action_links": {
                        "manual": "",
                        "API": "",
                        "UI": ""
                    }
                })
        
        # 2. –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –æ–±—ä–µ–∫—Ç—ã
        if "model_objects" in llm_model:
            for i, obj in enumerate(llm_model["model_objects"]):
                # LLM –º–æ–∂–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ä–∞–∑–Ω—ã–µ –∫–ª—é—á–∏
                object_id = obj.get("id") or obj.get("object_id") or f"o{i+1:05d}"
                object_name = obj.get("type") or obj.get("object_name") or obj.get("name") or f"–û–±—ä–µ–∫—Ç {i+1}"
                
                # –ï—Å–ª–∏ ID –Ω–µ –≤ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ, –∏—Å–ø—Ä–∞–≤–ª—è–µ–º
                if not object_id.startswith('o'):
                    object_id = f"o{i+1:05d}"
                
                # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏—è
                resource_state = []
                states = obj.get("states") or obj.get("resource_state") or []
                
                if isinstance(states, list):
                    for j, state in enumerate(states):
                        if isinstance(state, dict):
                            # –£–∂–µ —Å–ª–æ–≤–∞—Ä—å —Å state_id –∏ state_name
                            state_id = state.get("state_id") or f"s{j+1:05d}"
                            state_name = state.get("state_name") or state.get("name") or f"—Å–æ—Å—Ç–æ—è–Ω–∏–µ {j+1}"
                        else:
                            # –ü—Ä–æ—Å—Ç–æ —Å—Ç—Ä–æ–∫–∞ —Å –Ω–∞–∑–≤–∞–Ω–∏–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏—è
                            state_id = f"s{j+1:05d}"
                            state_name = str(state)
                        
                        resource_state.append({
                            "state_id": state_id,
                            "state_name": state_name
                        })
                
                # –ï—Å–ª–∏ –Ω–µ—Ç —Å–æ—Å—Ç–æ—è–Ω–∏–π, –¥–æ–±–∞–≤–ª—è–µ–º –¥–µ—Ñ–æ–ª—Ç–Ω—ã–µ
                if not resource_state:
                    resource_state = [
                        {"state_id": "s00001", "state_name": "–Ω–µ–∞–∫—Ç–∏–≤–µ–Ω"},
                        {"state_id": "s00002", "state_name": "–∞–∫—Ç–∏–≤–µ–Ω"}
                    ]
                
                model["model_objects"].append({
                    "object_id": object_id,
                    "object_name": object_name,
                    "resource_state": resource_state
                })
        
        # 3. –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Å–≤—è–∑–∏
        if "model_connections" in llm_model:
            for i, conn in enumerate(llm_model["model_connections"]):
                # LLM –º–æ–∂–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ä–∞–∑–Ω—ã–µ –∫–ª—é—á–∏
                connection_out = conn.get("connection_out") or conn.get("from") or conn.get("source")
                connection_in = conn.get("connection_in") or conn.get("to") or conn.get("target")
                
                if connection_out and connection_in:
                    # –ò—Å–ø—Ä–∞–≤–ª—è–µ–º ID –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
                    if connection_out.startswith('o') and 's' in connection_out and len(connection_out) > 6:
                        # –£–∂–µ —Å–æ—Å—Ç–∞–≤–Ω–æ–π ID: o00001s00001
                        pass
                    elif connection_out.startswith('o') and len(connection_out) == 6:
                        # –¢–æ–ª—å–∫–æ object_id, –¥–æ–±–∞–≤–ª—è–µ–º state_id
                        connection_out = f"{connection_out}s00001"
                    
                    if connection_in.startswith('a') and len(connection_in) == 6:
                        # –î–µ–π—Å—Ç–≤–∏–µ –≤ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ
                        pass
                    
                    model["model_connections"].append({
                        "connection_out": connection_out,
                        "connection_in": connection_in
                    })
        
        return model
    
    def save_model_to_file(self, model, model_name, append=False):
        """
        –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –º–æ–¥–µ–ª—å –≤ —Ñ–∞–π–ª JSON –≤ –ø–∞–ø–∫–µ models/
        
        Args:
            model: —Å–ª–æ–≤–∞—Ä—å —Å –º–æ–¥–µ–ª—å—é
            model_name: –∏–º—è –º–æ–¥–µ–ª–∏ (–∏–º—è —Ñ–∞–π–ª–∞)
            append: –µ—Å–ª–∏ True, –¥–æ–±–∞–≤–ª—è–µ—Ç –∫ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–º—É —Ñ–∞–π–ª—É
        """
        try:
            # –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫—É models, –µ—Å–ª–∏ –æ–Ω–∞ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
            models_dir = "models"
            if not os.path.exists(models_dir):
                os.makedirs(models_dir)
                print(f"üìÅ –°–æ–∑–¥–∞–Ω–∞ –ø–∞–ø–∫–∞: {models_dir}")
            
            # –°–æ–∑–¥–∞–µ–º –±–µ–∑–æ–ø–∞—Å–Ω–æ–µ –∏–º—è —Ñ–∞–π–ª–∞
            safe_name = "".join(c for c in model_name if c.isalnum() or c in "_- ").strip()
            if not safe_name:
                safe_name = "unnamed_model"
            
            filename = f"{models_dir}/{safe_name}.json"
            
            if append and os.path.exists(filename):
                # –ß–∏—Ç–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â—É—é –º–æ–¥–µ–ª—å
                try:
                    with open(filename, 'r', encoding='utf-8') as f:
                        existing_data = json.load(f)
                    
                    # –û–±—ä–µ–¥–∏–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ
                    existing_actions = existing_data.get("model_actions", [])
                    existing_objects = existing_data.get("model_objects", [])
                    existing_connections = existing_data.get("model_connections", [])
                    
                    # –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã –ø–æ ID
                    new_actions = model.get("model_actions", [])
                    new_objects = model.get("model_objects", [])
                    new_connections = model.get("model_connections", [])
                    
                    # –û–±—ä–µ–¥–∏–Ω—è–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã
                    combined_actions = self._merge_unique(existing_actions, new_actions, "action_id")
                    combined_objects = self._merge_unique(existing_objects, new_objects, "object_id")
                    combined_connections = self._merge_unique(existing_connections, new_connections, lambda x: f"{x.get('connection_out')}-{x.get('connection_in')}")
                    
                    # –û–±–Ω–æ–≤–ª—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
                    existing_data["metadata"]["updated_at"] = datetime.datetime.now().isoformat()
                    existing_data["metadata"]["chunks_processed"] = existing_data["metadata"].get("chunks_processed", 0) + 1
                    
                    model_with_metadata = {
                        "version": "1.0",
                        "metadata": existing_data["metadata"],
                        "model_actions": combined_actions,
                        "model_objects": combined_objects,
                        "model_connections": combined_connections
                    }
                    
                    print(f"üìù –î–æ–±–∞–≤–ª—è—é –∫ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–π –º–æ–¥–µ–ª–∏ (—á–∞–Ω–∫–æ–≤: {existing_data['metadata'].get('chunks_processed', 0)})")
                    
                except Exception as e:
                    print(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–≥–æ —Ñ–∞–π–ª–∞: {e}")
                    append = False
            
            if not append:
                # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—É—é –º–æ–¥–µ–ª—å —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏
                model_with_metadata = {
                    "version": "1.0",
                    "metadata": {
                        "name": safe_name,
                        "generated_at": datetime.datetime.now().isoformat(),
                        "source": "api_main.py",
                        "chunks_processed": 1
                    },
                    "model_actions": model.get("model_actions", []),
                    "model_objects": model.get("model_objects", []),
                    "model_connections": model.get("model_connections", [])
                }
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ —Ñ–∞–π–ª
            mode = "a" if append else "w"
            with open(filename, mode, encoding='utf-8') as f:
                if append:
                    # –ü–µ—Ä–µ–∑–∞–ø–∏—Å—ã–≤–∞–µ–º –≤–µ—Å—å —Ñ–∞–π–ª
                    f.seek(0)
                    f.truncate()
                json.dump(model_with_metadata, f, ensure_ascii=False, indent=2)
            
            print(f"üíæ –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ —Ñ–∞–π–ª: {filename}")
            print(f"üìä –†–∞–∑–º–µ—Ä: {os.path.getsize(filename)} –±–∞–π—Ç")
            
            return filename
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –º–æ–¥–µ–ª–∏: {e}")
            return None

    def _convert_to_enhanced_structure(self, model):
        """–ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç —Å—Ç–∞—Ä—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É –º–æ–¥–µ–ª–∏ –≤ –Ω–æ–≤—É—é —É–ª—É—á—à–µ–Ω–Ω—É—é"""
        print("   üîÑ –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –º–æ–¥–µ–ª–∏...")
        
        actions = model.get("model_actions", [])
        enhanced_actions = []
        
        for i, action in enumerate(actions):
            old_name = action.get("action_name", "–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ–µ –¥–µ–π—Å—Ç–≤–∏–µ")
            
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å—Ç–∞—Ä–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
            old_name_lower = old_name.lower()
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∞–∫—Ç–æ—Ä–∞
            action_actor = "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å"  # –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
            if "–∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä" in old_name_lower:
                action_actor = "–ê–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä"
            elif "–∏—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—å" in old_name_lower:
                action_actor = "–ò—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—å"
            elif "—Å–∏—Å—Ç–µ–º–∞" in old_name_lower:
                action_actor = "–°–∏—Å—Ç–µ–º–∞"
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –¥–µ–π—Å—Ç–≤–∏–µ
            action_action = old_name_lower
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –º–µ—Å—Ç–æ
            action_place = "–°–∏—Å—Ç–µ–º–∞"  # –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
            if "–±–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö" in old_name_lower:
                action_place = "–ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö"
            elif "—Å—Ç—Ä–∞–Ω–∏—Ü–∞" in old_name_lower:
                action_place = "–ì–ª–∞–≤–Ω–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞"
            
            # –°–æ–∑–¥–∞–µ–º —É–ª—É—á—à–µ–Ω–Ω–æ–µ –¥–µ–π—Å—Ç–≤–∏–µ
            enhanced_action = {
                "action_id": action.get("action_id", f"a{i+1:05d}"),
                "action_actor": action_actor,
                "action_action": action_action,
                "action_place": action_place,
                "action_links": action.get("action_links", {"manual": "", "API": "", "UI": ""}),
                "source_line": 0,
                "source_text": old_name
            }
            
            enhanced_actions.append(enhanced_action)
        
        # –û–±–Ω–æ–≤–ª—è–µ–º –º–æ–¥–µ–ª—å
        model["model_actions"] = enhanced_actions
        
        # –û–±–Ω–æ–≤–ª—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –∞–Ω–∞–ª–∏–∑–∞
        if "analysis_metadata" in model:
            model["analysis_metadata"]["structure_converted"] = True
            model["analysis_metadata"]["converted_at"] = datetime.datetime.now().isoformat()
        
        return model

    def _merge_unique(self, list1, list2, key_func):
        """–û–±—ä–µ–¥–∏–Ω—è–µ—Ç –¥–≤–∞ —Å–ø–∏—Å–∫–∞, —É–±–∏—Ä–∞—è –¥—É–±–ª–∏–∫–∞—Ç—ã –ø–æ –∫–ª—é—á—É"""
        if isinstance(key_func, str):
            # –ï—Å–ª–∏ key_func - —ç—Ç–æ —Å—Ç—Ä–æ–∫–∞, –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ–µ –∫–∞–∫ –∫–ª—é—á
            key_func = lambda x: x.get(key_func)
        
        merged = []
        seen_keys = set()
        
        # –î–æ–±–∞–≤–ª—è–µ–º —ç–ª–µ–º–µ–Ω—Ç—ã –∏–∑ –ø–µ—Ä–≤–æ–≥–æ —Å–ø–∏—Å–∫–∞
        for item in list1:
            key = key_func(item)
            if key not in seen_keys:
                seen_keys.add(key)
                merged.append(item)
        
        # –î–æ–±–∞–≤–ª—è–µ–º —ç–ª–µ–º–µ–Ω—Ç—ã –∏–∑ –≤—Ç–æ—Ä–æ–≥–æ —Å–ø–∏—Å–∫–∞
        for item in list2:
            key = key_func(item)
            if key not in seen_keys:
                seen_keys.add(key)
                merged.append(item)
        
        return merged

    def enhanced_stream_analysis(self, text, model_name):
        """
        –£–õ–£–ß–®–ï–ù–ù–´–ô –ø–æ—Ç–æ–∫–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑ —Ç–µ–∫—Å—Ç–∞ –¢–ó —Å –Ω–æ–≤–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä–æ–π
        –ú–∏–Ω–∏–º—É–º 500 —Å–∏–º–≤–æ–ª–æ–≤ –Ω–∞ —á–∞–Ω–∫, –∏–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
        """
        print("üîÑ –ó–ê–ü–£–°–ö –£–õ–£–ß–®–ï–ù–ù–û–ì–û –ü–û–¢–û–ö–û–í–û–ì–û –ê–ù–ê–õ–ò–ó–ê –¢–ó")
        print(f"üìÑ –û–±—â–∞—è –¥–ª–∏–Ω–∞ —Ç–µ–∫—Å—Ç–∞: {len(text)} —Å–∏–º–≤–æ–ª–æ–≤")
        
        # –†–∞–∑–±–∏–≤–∞–µ–º —Ç–µ–∫—Å—Ç –Ω–∞ –∞–±–∑–∞—Ü—ã
        paragraphs = text.split('\n\n')
        print(f"üìã –ù–∞–π–¥–µ–Ω–æ –∞–±–∑–∞—Ü–µ–≤: {len(paragraphs)}")
        
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º –∞–±–∑–∞—Ü—ã –≤ —á–∞–Ω–∫–∏ (–º–∏–Ω–∏–º—É–º 500 —Å–∏–º–≤–æ–ª–æ–≤)
        chunks = []
        current_chunk = ""
        current_length = 0
        
        for i, paragraph in enumerate(paragraphs):
            paragraph = paragraph.strip()
            if not paragraph:
                continue
                
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ –∞–±–∑–∞—Ü –Ω–∞—á–∞–ª–æ–º –Ω–æ–≤–æ–π –≥–ª–∞–≤—ã/—Ä–∞–∑–¥–µ–ª–∞
            is_new_section = False
            if paragraph and paragraph[0].isdigit() and ('.' in paragraph[:10] or ')' in paragraph[:10]):
                # –ù–æ–º–µ—Ä–æ–≤–∞–Ω–Ω—ã–π –ø—É–Ω–∫—Ç (1., 2., 3. –∏ —Ç.–¥.)
                is_new_section = True
            elif paragraph.lower().startswith(('–≥–ª–∞–≤–∞', '—Ä–∞–∑–¥–µ–ª', '—á–∞—Å—Ç—å', '—Ñ—É–Ω–∫—Ü–∏—è', '—Ç—Ä–µ–±–æ–≤–∞–Ω–∏–µ')):
                is_new_section = True
            
            # –ï—Å–ª–∏ —Ç–µ–∫—É—â–∏–π —á–∞–Ω–∫ —Å–ª–∏—à–∫–æ–º –º–∞–ª, –Ω–æ —ç—Ç–æ –Ω–æ–≤—ã–π —Ä–∞–∑–¥–µ–ª - –Ω–∞—á–∏–Ω–∞–µ–º –Ω–æ–≤—ã–π —á–∞–Ω–∫
            if current_length < 500 and is_new_section and current_chunk:
                chunks.append(current_chunk)
                print(f"   üì¶ –ß–∞–Ω–∫ {len(chunks)}: {len(current_chunk)} —Å–∏–º–≤–æ–ª–æ–≤ (–Ω–æ–≤—ã–π —Ä–∞–∑–¥–µ–ª)")
                current_chunk = ""
                current_length = 0
            
            # –î–æ–±–∞–≤–ª—è–µ–º –∞–±–∑–∞—Ü –∫ —Ç–µ–∫—É—â–µ–º—É —á–∞–Ω–∫—É
            if current_chunk:
                current_chunk += "\n\n" + paragraph
            else:
                current_chunk = paragraph
            current_length += len(paragraph)
            
            # –ï—Å–ª–∏ –¥–æ—Å—Ç–∏–≥–ª–∏ –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞ - —Å–æ—Ö—Ä–∞–Ω—è–µ–º —á–∞–Ω–∫
            if current_length >= 500:
                chunks.append(current_chunk)
                print(f"   üì¶ –ß–∞–Ω–∫ {len(chunks)}: {current_length} —Å–∏–º–≤–æ–ª–æ–≤")
                current_chunk = ""
                current_length = 0
        
        # –î–æ–±–∞–≤–ª—è–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π —á–∞–Ω–∫, –µ—Å–ª–∏ –æ–Ω –Ω–µ –ø—É—Å—Ç–æ–π
        if current_chunk:
            chunks.append(current_chunk)
            print(f"   üì¶ –ß–∞–Ω–∫ {len(chunks)}: {len(current_chunk)} —Å–∏–º–≤–æ–ª–æ–≤ (–ø–æ—Å–ª–µ–¥–Ω–∏–π)")
        
        print(f"üéØ –ò—Ç–æ–≥–æ —á–∞–Ω–∫–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {len(chunks)}")
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥—ã–π —á–∞–Ω–∫ –∏ –∏–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω–æ —Å–æ—Ö—Ä–∞–Ω—è–µ–º
        total_actions = 0
        total_objects = 0
        total_connections = 0
        
        for i, chunk in enumerate(chunks):
            print(f"\nüîç –û–ë–†–ê–ë–û–¢–ö–ê –ß–ê–ù–ö–ê {i+1}/{len(chunks)}:")
            print(f"   üìè –î–ª–∏–Ω–∞: {len(chunk)} —Å–∏–º–≤–æ–ª–æ–≤")
            print(f"   üìù –°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ (–ø–µ—Ä–≤—ã–µ 100 —Å–∏–º–≤–æ–ª–æ–≤): {chunk[:100]}...")
            
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —á–∞–Ω–∫ —Å –£–õ–£–ß–®–ï–ù–ù–´–ú –º–µ—Ç–æ–¥–æ–º
            chunk_result = self.simple_text_analysis(chunk)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏ –≥–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ–º –Ω–æ–≤—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É
            actions = chunk_result.get("model_actions", [])
            if actions and "action_actor" not in actions[0]:
                print(f"   ‚ö†Ô∏è  –ü–†–ï–î–£–ü–†–ï–ñ–î–ï–ù–ò–ï: –ò—Å–ø–æ–ª—å–∑—É—é –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã")
                chunk_result = self._convert_to_enhanced_structure(chunk_result)
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
            chunk_actions = len(actions)
            chunk_objects = len(chunk_result.get("model_objects", []))
            chunk_connections = len(chunk_result.get("model_connections", []))
            
            total_actions += chunk_actions
            total_objects += chunk_objects
            total_connections += chunk_connections
            
            print(f"   üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —á–∞–Ω–∫–∞: {chunk_actions} –¥–µ–π—Å—Ç–≤–∏–π, {chunk_objects} –æ–±—ä–µ–∫—Ç–æ–≤, {chunk_connections} —Å–≤—è–∑–µ–π")
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–∏–º–µ—Ä –¥–µ–π—Å—Ç–≤–∏—è, –µ—Å–ª–∏ –µ—Å—Ç—å
            if actions:
                first_action = actions[0]
                print(f"   üìù –ü—Ä–∏–º–µ—Ä: {first_action.get('action_actor', '?')} {first_action.get('action_action', '?')} {first_action.get('action_place', '?')}")
            
            # –ò–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω–æ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å
            append = (i > 0)  # –ü–µ—Ä–≤—ã–π —á–∞–Ω–∫ —Å–æ–∑–¥–∞–µ—Ç —Ñ–∞–π–ª, –æ—Å—Ç–∞–ª—å–Ω—ã–µ –¥–æ–±–∞–≤–ª—è—é—Ç
            saved_filename = self.save_model_to_file(chunk_result, model_name, append=append)
            
            if saved_filename:
                print(f"   üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤: {saved_filename} (—á–∞–Ω–∫ {i+1})")
            else:
                print(f"   ‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —á–∞–Ω–∫–∞ {i+1}")
            
            # –ù–µ–±–æ–ª—å—à–∞—è –ø–∞—É–∑–∞ –º–µ–∂–¥—É —á–∞–Ω–∫–∞–º–∏ –¥–ª—è –Ω–∞–≥–ª—è–¥–Ω–æ—Å—Ç–∏
            if i < len(chunks) - 1:
                print("   ‚è≥ –ü–µ—Ä–µ—Ö–æ–¥ –∫ —Å–ª–µ–¥—É—é—â–µ–º—É —á–∞–Ω–∫—É...")
        
        print(f"\n‚úÖ –£–õ–£–ß–®–ï–ù–ù–´–ô –ü–û–¢–û–ö–û–í–´–ô –ê–ù–ê–õ–ò–ó –ó–ê–í–ï–†–®–ï–ù!")
        print(f"üìä –ò–¢–û–ì–û –û–ë–†–ê–ë–û–¢–ê–ù–û:")
        print(f"   ‚Ä¢ –ß–∞–Ω–∫–æ–≤: {len(chunks)}")
        print(f"   ‚Ä¢ –î–µ–π—Å—Ç–≤–∏–π: {total_actions}")
        print(f"   ‚Ä¢ –û–±—ä–µ–∫—Ç–æ–≤: {total_objects}")
        print(f"   ‚Ä¢ –°–≤—è–∑–µ–π: {total_connections}")
        
        # –ß–∏—Ç–∞–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—É—é –º–æ–¥–µ–ª—å –¥–ª—è –≤–æ–∑–≤—Ä–∞—Ç–∞
        try:
            if saved_filename and os.path.exists(saved_filename):
                with open(saved_filename, 'r', encoding='utf-8') as f:
                    final_model = json.load(f)
                
                # –î–æ–±–∞–≤–ª—è–µ–º –æ–±—â—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
                final_model["metadata"]["total_chunks"] = len(chunks)
                final_model["metadata"]["total_actions"] = total_actions
                final_model["metadata"]["total_objects"] = total_objects
                final_model["metadata"]["total_connections"] = total_connections
                final_model["metadata"]["analysis_method"] = "enhanced_stream_analysis"
                
                # –ü–µ—Ä–µ—Å–æ—Ö—Ä–∞–Ω—è–µ–º —Å –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–º–∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏
                with open(saved_filename, 'w', encoding='utf-8') as f:
                    json.dump(final_model, f, ensure_ascii=False, indent=2)
                
                print(f"\nüíæ –§–ò–ù–ê–õ–¨–ù–ê–Ø –ú–û–î–ï–õ–¨ –°–û–•–†–ê–ù–ï–ù–ê: {saved_filename}")
                
                return final_model
        except Exception as e:
            print(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∏–Ω–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏: {e}")
        
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∫–∞–∫ –∑–∞–ø–∞—Å–Ω–æ–π –≤–∞—Ä–∏–∞–Ω—Ç
        return chunk_result

    def stream_text_analysis(self, text, model_name):
        """–°–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å: –≤—ã–∑—ã–≤–∞–µ—Ç —É–ª—É—á—à–µ–Ω–Ω—É—é –≤–µ—Ä—Å–∏—é"""
        return self.enhanced_stream_analysis(text, model_name)

    def enhanced_stream_analysis(self, text, model_name):
        """
        –ü–æ—Ç–æ–∫–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑ —Ç–µ–∫—Å—Ç–∞ –¢–ó –ø–æ —á–∞—Å—Ç—è–º (–º–∏–Ω–∏–º—É–º 500 —Å–∏–º–≤–æ–ª–æ–≤)
        –°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω–æ
        """
        print("üîÑ –ó–ê–ü–£–°–ö –ü–û–¢–û–ö–û–í–û–ì–û –ê–ù–ê–õ–ò–ó–ê –¢–ó")
        print(f"üìÑ –û–±—â–∞—è –¥–ª–∏–Ω–∞ —Ç–µ–∫—Å—Ç–∞: {len(text)} —Å–∏–º–≤–æ–ª–æ–≤")
        
        # –†–∞–∑–±–∏–≤–∞–µ–º —Ç–µ–∫—Å—Ç –Ω–∞ –∞–±–∑–∞—Ü—ã
        paragraphs = text.split('\n\n')
        print(f"üìã –ù–∞–π–¥–µ–Ω–æ –∞–±–∑–∞—Ü–µ–≤: {len(paragraphs)}")
        
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º –∞–±–∑–∞—Ü—ã –≤ —á–∞–Ω–∫–∏ (–º–∏–Ω–∏–º—É–º 500 —Å–∏–º–≤–æ–ª–æ–≤)
        chunks = []
        current_chunk = ""
        current_length = 0
        
        for i, paragraph in enumerate(paragraphs):
            paragraph = paragraph.strip()
            if not paragraph:
                continue
                
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ –∞–±–∑–∞—Ü –Ω–∞—á–∞–ª–æ–º –Ω–æ–≤–æ–π –≥–ª–∞–≤—ã/—Ä–∞–∑–¥–µ–ª–∞
            is_new_section = False
            if paragraph and paragraph[0].isdigit() and ('.' in paragraph[:10] or ')' in paragraph[:10]):
                # –ù–æ–º–µ—Ä–æ–≤–∞–Ω–Ω—ã–π –ø—É–Ω–∫—Ç (1., 2., 3. –∏ —Ç.–¥.)
                is_new_section = True
            elif paragraph.lower().startswith(('–≥–ª–∞–≤–∞', '—Ä–∞–∑–¥–µ–ª', '—á–∞—Å—Ç—å', '—Ñ—É–Ω–∫—Ü–∏—è', '—Ç—Ä–µ–±–æ–≤–∞–Ω–∏–µ')):
                is_new_section = True
            
            # –ï—Å–ª–∏ —Ç–µ–∫—É—â–∏–π —á–∞–Ω–∫ —Å–ª–∏—à–∫–æ–º –º–∞–ª, –Ω–æ —ç—Ç–æ –Ω–æ–≤—ã–π —Ä–∞–∑–¥–µ–ª - –Ω–∞—á–∏–Ω–∞–µ–º –Ω–æ–≤—ã–π —á–∞–Ω–∫
            if current_length < 500 and is_new_section and current_chunk:
                chunks.append(current_chunk)
                print(f"   üì¶ –ß–∞–Ω–∫ {len(chunks)}: {len(current_chunk)} —Å–∏–º–≤–æ–ª–æ–≤ (–Ω–æ–≤—ã–π —Ä–∞–∑–¥–µ–ª)")
                current_chunk = ""
                current_length = 0
            
            # –î–æ–±–∞–≤–ª—è–µ–º –∞–±–∑–∞—Ü –∫ —Ç–µ–∫—É—â–µ–º—É —á–∞–Ω–∫—É
            if current_chunk:
                current_chunk += "\n\n" + paragraph
            else:
                current_chunk = paragraph
            current_length += len(paragraph)
            
            # –ï—Å–ª–∏ –¥–æ—Å—Ç–∏–≥–ª–∏ –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞ - —Å–æ—Ö—Ä–∞–Ω—è–µ–º —á–∞–Ω–∫
            if current_length >= 500:
                chunks.append(current_chunk)
                print(f"   üì¶ –ß–∞–Ω–∫ {len(chunks)}: {current_length} —Å–∏–º–≤–æ–ª–æ–≤")
                current_chunk = ""
                current_length = 0
        
        # –î–æ–±–∞–≤–ª—è–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π —á–∞–Ω–∫, –µ—Å–ª–∏ –æ–Ω –Ω–µ –ø—É—Å—Ç–æ–π
        if current_chunk:
            chunks.append(current_chunk)
            print(f"   üì¶ –ß–∞–Ω–∫ {len(chunks)}: {len(current_chunk)} —Å–∏–º–≤–æ–ª–æ–≤ (–ø–æ—Å–ª–µ–¥–Ω–∏–π)")
        
        print(f"üéØ –ò—Ç–æ–≥–æ —á–∞–Ω–∫–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {len(chunks)}")
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥—ã–π —á–∞–Ω–∫ –∏ –∏–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω–æ —Å–æ—Ö—Ä–∞–Ω—è–µ–º
        total_actions = 0
        total_objects = 0
        total_connections = 0
        
        for i, chunk in enumerate(chunks):
            print(f"\nüîç –û–ë–†–ê–ë–û–¢–ö–ê –ß–ê–ù–ö–ê {i+1}/{len(chunks)}:")
            print(f"   üìè –î–ª–∏–Ω–∞: {len(chunk)} —Å–∏–º–≤–æ–ª–æ–≤")
            print(f"   üìù –°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ (–ø–µ—Ä–≤—ã–µ 100 —Å–∏–º–≤–æ–ª–æ–≤): {chunk[:100]}...")
            
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —á–∞–Ω–∫ —Å –£–õ–£–ß–®–ï–ù–ù–´–ú –º–µ—Ç–æ–¥–æ–º
            chunk_result = self.simple_text_analysis(chunk)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Å–æ–¥–µ—Ä–∂–∏—Ç –Ω–æ–≤—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É
            if chunk_result.get("model_actions"):
                first_action = chunk_result["model_actions"][0]
                if "action_actor" not in first_action:
                    print(f"   ‚ö†Ô∏è  –ü–†–ï–î–£–ü–†–ï–ñ–î–ï–ù–ò–ï: –†–µ–∑—É–ª—å—Ç–∞—Ç –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç —É–ª—É—á—à–µ–Ω–Ω—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É!")
                    # –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –∫ –Ω–æ–≤–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä–µ
                    self._convert_to_enhanced_structure(chunk_result)
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
            chunk_actions = len(chunk_result.get("model_actions", []))
            chunk_objects = len(chunk_result.get("model_objects", []))
            chunk_connections = len(chunk_result.get("model_connections", []))
            
            total_actions += chunk_actions
            total_objects += chunk_objects
            total_connections += chunk_connections
            
            print(f"   üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —á–∞–Ω–∫–∞: {chunk_actions} –¥–µ–π—Å—Ç–≤–∏–π, {chunk_objects} –æ–±—ä–µ–∫—Ç–æ–≤, {chunk_connections} —Å–≤—è–∑–µ–π")
            
            # –ò–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω–æ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å
            append = (i > 0)  # –ü–µ—Ä–≤—ã–π —á–∞–Ω–∫ —Å–æ–∑–¥–∞–µ—Ç —Ñ–∞–π–ª, –æ—Å—Ç–∞–ª—å–Ω—ã–µ –¥–æ–±–∞–≤–ª—è—é—Ç
            saved_filename = self.save_model_to_file(chunk_result, model_name, append=append)
            
            if saved_filename:
                print(f"   üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤: {saved_filename} (—á–∞–Ω–∫ {i+1})")
            else:
                print(f"   ‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —á–∞–Ω–∫–∞ {i+1}")
            
            # –ù–µ–±–æ–ª—å—à–∞—è –ø–∞—É–∑–∞ –º–µ–∂–¥—É —á–∞–Ω–∫–∞–º–∏ –¥–ª—è –Ω–∞–≥–ª—è–¥–Ω–æ—Å—Ç–∏
            if i < len(chunks) - 1:
                print("   ‚è≥ –ü–µ—Ä–µ—Ö–æ–¥ –∫ —Å–ª–µ–¥—É—é—â–µ–º—É —á–∞–Ω–∫—É...")
        
        print(f"\n‚úÖ –ü–û–¢–û–ö–û–í–´–ô –ê–ù–ê–õ–ò–ó –ó–ê–í–ï–†–®–ï–ù!")
        print(f"üìä –ò–¢–û–ì–û –û–ë–†–ê–ë–û–¢–ê–ù–û:")
        print(f"   ‚Ä¢ –ß–∞–Ω–∫–æ–≤: {len(chunks)}")
        print(f"   ‚Ä¢ –î–µ–π—Å—Ç–≤–∏–π: {total_actions}")
        print(f"   ‚Ä¢ –û–±—ä–µ–∫—Ç–æ–≤: {total_objects}")
        print(f"   ‚Ä¢ –°–≤—è–∑–µ–π: {total_connections}")
        
        # –ß–∏—Ç–∞–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—É—é –º–æ–¥–µ–ª—å –¥–ª—è –≤–æ–∑–≤—Ä–∞—Ç–∞
        try:
            if saved_filename and os.path.exists(saved_filename):
                with open(saved_filename, 'r', encoding='utf-8') as f:
                    final_model = json.load(f)
                
                # –î–æ–±–∞–≤–ª—è–µ–º –æ–±—â—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
                final_model["metadata"]["total_chunks"] = len(chunks)
                final_model["metadata"]["total_actions"] = total_actions
                final_model["metadata"]["total_objects"] = total_objects
                final_model["metadata"]["total_connections"] = total_connections
                
                # –ü–µ—Ä–µ—Å–æ—Ö—Ä–∞–Ω—è–µ–º —Å –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–º–∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏
                with open(saved_filename, 'w', encoding='utf-8') as f:
                    json.dump(final_model, f, ensure_ascii=False, indent=2)
                
                return final_model
        except Exception as e:
            print(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∏–Ω–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏: {e}")
        
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∫–∞–∫ –∑–∞–ø–∞—Å–Ω–æ–π –≤–∞—Ä–∏–∞–Ω—Ç
        return chunk_result

"""
–ù–æ–≤—ã–π –º–µ—Ç–æ–¥ simple_text_analysis –ë–ï–ó –º–æ–∫-–¥–∞–Ω–Ω—ã—Ö
"""

import datetime

def simple_text_analysis(self, text):
    """
    –†–ï–ê–õ–¨–ù–´–ô –∞–Ω–∞–ª–∏–∑ —Ç–µ–∫—Å—Ç–∞ –¢–ó –ë–ï–ó –ú–û–ö-–î–ê–ù–ù–´–•
    
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–æ–ª—å–∫–æ —Ç–æ, —á—Ç–æ —Ä–µ–∞–ª—å–Ω–æ –Ω–∞–π–¥–µ–Ω–æ –≤ —Ç–µ–∫—Å—Ç–µ.
    –ï—Å–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ - –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø—É—Å—Ç—ã–µ —Å–ø–∏—Å–∫–∏.
    """
    print("üîç –ó–ê–ü–£–°–ö –†–ï–ê–õ–¨–ù–û–ì–û –ê–ù–ê–õ–ò–ó–ê –¢–ï–ö–°–¢–ê –¢–ó (–ë–ï–ó –ú–û–ö-–î–ê–ù–ù–´–•)")
    print(f"üìÑ –î–ª–∏–Ω–∞ —Ç–µ–∫—Å—Ç–∞: {len(text)} —Å–∏–º–≤–æ–ª–æ–≤")
    
    # –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞
    actions = []
    objects = []
    connections = []
    
    lines = text.split('\n')
    action_counter = 1
    object_counter = 1
    state_counter = 1
    
    # 1. –ü–û–ò–°–ö –î–ï–ô–°–¢–í–ò–ô (—Ç–æ–ª—å–∫–æ —Ä–µ–∞–ª—å–Ω—ã–µ, –∏–∑ —Ç–µ–∫—Å—Ç–∞)
    print("üîç –ü–æ–∏—Å–∫ –†–ï–ê–õ–¨–ù–´–• –¥–µ–π—Å—Ç–≤–∏–π –≤ —Ç–µ–∫—Å—Ç–µ...")
    
    found_actions = []
    action_keywords = [
        '—Å–æ–∑–¥–∞', '–¥–æ–±–∞–≤', '–∏–∑–º–µ–Ω', '—É–¥–∞–ª—è', '–Ω–∞–∑–Ω–∞—á–∞',
        '–ø—Ä–æ–≤–µ—Ä—è', '—Å–æ—Ö—Ä–∞–Ω—è', '–æ—Ç–ø—Ä–∞–≤–ª—è', '–ø–æ–ª—É—á–∞', '–≥–µ–Ω–µ—Ä',
        '—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä—É', '–∞–Ω–∞–ª–∏–∑–∏—Ä—É', '—Ñ–æ—Ä–º–∏—Ä—É', '—ç–∫—Å–ø–æ—Ä—Ç–∏—Ä',
        '–∏–º–ø–æ—Ä—Ç–∏—Ä', '—É–ø—Ä–∞–≤–ª—è', '–∫–æ–Ω—Ç—Ä–æ–ª–∏—Ä—É', '–æ—Ç—Å–ª–µ–∂–∏–≤–∞',
        '–≤—ã–ø–æ–ª–Ω—è', '–∑–∞–≤–µ—Ä—à–∞', '–Ω–∞—á–∏–Ω–∞', '–ø—Ä–µ–∫—Ä–∞—â–∞'
    ]
    
    actor_keywords = [
        '–ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å', '–∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä', '–∏—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—å',
        '—Å–∏—Å—Ç–µ–º–∞', '—Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫', '—Ç–µ—Å—Ç–∏—Ä–æ–≤—â–∏–∫',
        '–∫–ª–∏–µ–Ω—Ç', '—Å–æ—Ç—Ä—É–¥–Ω–∏–∫', '–º–µ–Ω–µ–¥–∂–µ—Ä', '–æ–ø–µ—Ä–∞—Ç–æ—Ä'
    ]
    
    place_keywords = [
        '–≥–ª–∞–≤–Ω–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞', '–ø–∞–Ω–µ–ª—å —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è', '–±–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö',
        '–ª–∏—á–Ω—ã–π –∫–∞–±–∏–Ω–µ—Ç', '—Å–∏—Å—Ç–µ–º–∞', '–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å',
        '–∞–¥–º–∏–Ω –ø–∞–Ω–µ–ª—å', '–≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å', '–º–æ–±–∏–ª—å–Ω–æ–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ',
        '—Å–µ—Ä–≤–µ—Ä', '–∫–ª–∏–µ–Ω—Ç', '–±—Ä–∞—É–∑–µ—Ä'
    ]
    
    for i, line in enumerate(lines):
        line = line.strip()
        if not line:
            continue
        
        line_lower = line.lower()
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å–æ–¥–µ—Ä–∂–∏—Ç –ª–∏ —Å—Ç—Ä–æ–∫–∞ –¥–µ–π—Å—Ç–≤–∏–µ
        contains_action = any(keyword in line_lower for keyword in action_keywords)
        
        if contains_action:
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç
            actor = None
            action = line[:100]  # –ë–µ—Ä–µ–º —á–∞—Å—Ç—å —Å—Ç—Ä–æ–∫–∏
            place = "–°–∏—Å—Ç–µ–º–∞"
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∞–∫—Ç–æ—Ä–∞
            for actor_keyword in actor_keywords:
                if actor_keyword in line_lower:
                    actor = actor_keyword.capitalize()
                    break
            
            # –ï—Å–ª–∏ –∞–∫—Ç–æ—Ä –Ω–µ –Ω–∞–π–¥–µ–Ω, –∏—â–µ–º –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ
            if not actor:
                # –ò—â–µ–º –≤ –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö —Å—Ç—Ä–æ–∫–∞—Ö
                for j in range(max(0, i-3), i):
                    prev_line = lines[j].lower() if j < len(lines) else ""
                    for actor_keyword in actor_keywords:
                        if actor_keyword in prev_line:
                            actor = actor_keyword.capitalize()
                            break
                    if actor:
                        break
            
            if not actor:
                actor = "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å"
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –º–µ—Å—Ç–æ
            for place_keyword in place_keywords:
                if place_keyword in line_lower:
                    place = place_keyword.capitalize()
                    break
            
            # –°–æ–∑–¥–∞–µ–º –¥–µ–π—Å—Ç–≤–∏–µ
            action_id = f"a{action_counter:05d}"
            action_counter += 1
            
            action_data = {
                "action_id": action_id,
                "action_actor": actor,
                "action_action": action[:50],  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É
                "action_place": place,
                "action_links": {
                    "manual": f"–ò–∑ –¢–ó: —Å—Ç—Ä–æ–∫–∞ {i+1}",
                    "API": "",
                    "UI": ""
                },
                "source_line": i + 1,
                "source_text": line[:100]
            }
            
            found_actions.append(action_data)
            print(f"   ‚úÖ –ù–∞–π–¥–µ–Ω–æ –¥–µ–π—Å—Ç–≤–∏–µ: {actor} {action[:30]}... ({place})")
    
    actions = found_actions
    
    # 2. –ü–û–ò–°–ö –û–ë–™–ï–ö–¢–û–í (—Ç–æ–ª—å–∫–æ —Ä–µ–∞–ª—å–Ω—ã–µ, –∏–∑ —Ç–µ–∫—Å—Ç–∞)
    print("\nüîç –ü–æ–∏—Å–∫ –†–ï–ê–õ–¨–ù–´–• –æ–±—ä–µ–∫—Ç–æ–≤ –≤ —Ç–µ–∫—Å—Ç–µ...")
    
    found_objects = []
    object_keywords = [
        '–∑–∞–¥–∞—á–∞', '–¥–æ–∫—É–º–µ–Ω—Ç', '–ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å', '—Å–∏—Å—Ç–µ–º–∞',
        '–∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä', '–∏—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—å', '–æ—Ç—á–µ—Ç', '—Ñ–∞–π–ª',
        '—É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ', '–∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π', '—Å—Ç–∞—Ç—É—Å', '–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç',
        '–±–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö', '–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å', '–∫–ª–∏–µ–Ω—Ç', '—Å–µ—Ä–≤–µ—Ä'
    ]
    
    # –°–æ–±–∏—Ä–∞–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –æ–±—ä–µ–∫—Ç—ã –∏–∑ –≤—Å–µ–≥–æ —Ç–µ–∫—Å—Ç–∞
    text_lower = text.lower()
    unique_objects = set()
    
    for obj_keyword in object_keywords:
        if obj_keyword in text_lower:
            unique_objects.add(obj_keyword.capitalize())
    
    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ –æ–±—ä–µ–∫—Ç—ã –º–æ–¥–µ–ª–∏
    for obj_name in unique_objects:
        object_id = f"o{object_counter:05d}"
        object_counter += 1
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –≤–æ–∑–º–æ–∂–Ω—ã–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–∏–ø–∞ –æ–±—ä–µ–∫—Ç–∞
        states = []
        
        if obj_name.lower() in ['–ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å', '–∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä', '–∏—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—å']:
            states = [
                {"state_id": f"s{state_counter:05d}", "state_name": "–Ω–µ–∞–∫—Ç–∏–≤–µ–Ω"},
                {"state_id": f"s{state_counter+1:05d}", "state_name": "–∞–∫—Ç–∏–≤–µ–Ω"}
            ]
            state_counter += 2
        elif obj_name.lower() in ['–∑–∞–¥–∞—á–∞', '–¥–æ–∫—É–º–µ–Ω—Ç']:
            states = [
                {"state_id": f"s{state_counter:05d}", "state_name": "–Ω–µ —Å–æ–∑–¥–∞–Ω–∞"},
                {"state_id": f"s{state_counter+1:05d}", "state_name": "–≤ —Ä–∞–±–æ—Ç–µ"},
                {"state_id": f"s{state_counter+2:05d}", "state_name": "–∑–∞–≤–µ—Ä—à–µ–Ω–∞"}
            ]
            state_counter += 3
        elif obj_name.lower() in ['—Å–∏—Å—Ç–µ–º–∞', '–±–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö']:
            states = [
                {"state_id": f"s{state_counter:05d}", "state_name": "–Ω–µ–∞–∫—Ç–∏–≤–Ω–∞"},
                {"state_id": f"s{state_counter+1:05d}", "state_name": "–∞–∫—Ç–∏–≤–Ω–∞"}
            ]
            state_counter += 2
        else:
            states = [
                {"state_id": f"s{state_counter:05d}", "state_name": "–Ω–µ —Å–æ–∑–¥–∞–Ω"},
                {"state_id": f"s{state_counter+1:05d}", "state_name": "—Å–æ–∑–¥–∞–Ω"}
            ]
            state_counter += 2
        
        obj_data = {
            "object_id": object_id,
            "object_name": obj_name,
            "object_type": obj_name.lower(),
            "resource_state": states,
            "possible_states": [s["state_name"] for s in states]
        }
        
        found_objects.append(obj_data)
        print(f"   ‚úÖ –ù–∞–π–¥–µ–Ω –æ–±—ä–µ–∫—Ç: {obj_name}")
    
    objects = found_objects
    
    # 3. –°–û–ó–î–ê–ù–ò–ï –°–í–Ø–ó–ï–ô (—Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –µ—Å—Ç—å –∏ –¥–µ–π—Å—Ç–≤–∏—è, –∏ –æ–±—ä–µ–∫—Ç—ã)
    print("\nüîó –°–æ–∑–¥–∞–Ω–∏–µ –†–ï–ê–õ–¨–ù–´–• —Å–≤—è–∑–µ–π...")
    
    found_connections = []
    
    if actions and objects:
        # –ü—Ä–æ—Å—Ç–∞—è –ª–æ–≥–∏–∫–∞: —Å–≤—è–∑—ã–≤–∞–µ–º –¥–µ–π—Å—Ç–≤–∏—è —Å –æ–±—ä–µ–∫—Ç–∞–º–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        for action in actions:
            action_id = action["action_id"]
            action_text = action["action_action"].lower()
            
            for obj in objects:
                obj_name = obj["object_name"].lower()
                
                # –ï—Å–ª–∏ –Ω–∞–∑–≤–∞–Ω–∏–µ –æ–±—ä–µ–∫—Ç–∞ —É–ø–æ–º–∏–Ω–∞–µ—Ç—Å—è –≤ –¥–µ–π—Å—Ç–≤–∏–∏
                if obj_name in action_text:
                    # –°–≤—è–∑—ã–≤–∞–µ–º –¥–µ–π—Å—Ç–≤–∏–µ —Å –ø–µ—Ä–≤—ã–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ–º –æ–±—ä–µ–∫—Ç–∞
                    for state in obj["resource_state"]:
                        connection_id = f"c{len(found_connections)+1:05d}"
                        
                        connection = {
                            "connection_id": connection_id,
                            "connection_out": action_id,
                            "connection_in": f"{obj['object_id']}{state['state_id']}",
                            "description": f"{action['action_actor']} {action['action_action']} ‚Üí {obj['object_name']} {state['state_name']}",
                            "type": "affects"
                        }
                        
                        found_connections.append(connection)
                        print(f"   üîó –°–æ–∑–¥–∞–Ω–∞ —Å–≤—è–∑—å: {action['action_actor']} {action['action_action'][:20]}... ‚Üí {obj['object_name']}")
                        break
                    break
    
    connections = found_connections
    
    # 4. –ò–¢–û–ì–û–í–´–ô –û–¢–ß–ï–¢
    print("\nüìä –†–ï–ó–£–õ–¨–¢–ê–¢–´ –†–ï–ê–õ–¨–ù–û–ì–û –ê–ù–ê–õ–ò–ó–ê:")
    print(f"   ‚úÖ –î–µ–π—Å—Ç–≤–∏–π –Ω–∞–π–¥–µ–Ω–æ: {len(actions)}")
    print(f"   ‚úÖ –û–±—ä–µ–∫—Ç–æ–≤ –Ω–∞–π–¥–µ–Ω–æ: {len(objects)}")
    print(f"   ‚úÖ –°–≤—è–∑–µ–π —Å–æ–∑–¥–∞–Ω–æ: {len(connections)}")
    
    if len(actions) == 0:
        print("\n‚ö†Ô∏è  –í–ù–ò–ú–ê–ù–ò–ï: –í —Ç–µ–∫—Å—Ç–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –¥–µ–π—Å—Ç–≤–∏–π!")
        print("   –ü—Ä–æ–≤–µ—Ä—å—Ç–µ, —Å–æ–¥–µ—Ä–∂–∏—Ç –ª–∏ –¢–ó –æ–ø–∏—Å–∞–Ω–∏—è –¥–µ–π—Å—Ç–≤–∏–π (—Å–æ–∑–¥–∞–µ—Ç, –∏–∑–º–µ–Ω—è–µ—Ç, —É–¥–∞–ª—è–µ—Ç –∏ —Ç.–¥.)")
    
    # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
    return {
        "model_actions": actions,
        "model_objects": objects,
        "model_connections": connections,
        "analysis_metadata": {
            "analysis_method": "real_text_analysis",
            "analyzed_at": datetime.datetime.now().isoformat(),
            "text_length": len(text),
            "lines_processed": len(lines),
            "actions_found": len(actions),
            "objects_found": len(objects),
            "connections_created": len(connections),
            "warning": "–ë–ï–ó –ú–û–ö-–î–ê–ù–ù–´–•: –≤—Å–µ –¥–∞–Ω–Ω—ã–µ –∏–∑–≤–ª–µ—á–µ–Ω—ã –∏–∑ —Ç–µ–∫—Å—Ç–∞" if actions else "–í–ù–ò–ú–ê–ù–ò–ï: –¥–µ–π—Å—Ç–≤–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ —Ç–µ–∫—Å—Ç–µ"
        }
    }

def run_server(port=5001):
    """–ó–∞–ø—É—Å–∫ —Ç–µ—Å—Ç–æ–≤–æ–≥–æ —Å–µ—Ä–≤–µ—Ä–∞"""
    handler = TestAPIHandler
    
    for p in range(port, port + 20):
        try:
            server = socketserver.TCPServer(("", p), handler)
            print(f"‚úÖ –¢–ï–°–¢–û–í–´–ô API –∑–∞–ø—É—â–µ–Ω –Ω–∞ –ø–æ—Ä—Ç—É {p}")
            print(f"üì° GET  http://localhost:{p}/api/health")
            print(f"üì° POST http://localhost:{p}/api/generate-model")
            print("üõë –î–ª—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∏: Ctrl+C")
            sys.stdout.flush()
            
            # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –ø–æ—Ä—Ç
            with open('api_port.txt', 'w') as f:
                f.write(str(p))
            sys.stdout.flush()
            
            server.serve_forever()
            break
        except OSError as e:
            if "Address already in use" in str(e):
                continue
            else:
                raise

if __name__ == "__main__":
    run_server()